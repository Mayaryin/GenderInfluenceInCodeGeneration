{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Fine Tune\n",
    "- RoBERTa\n",
    "- No need for inference speed up using distil bert since dataset is very small\n",
    "- Hyperparameter tuning using huggingfaces hyperparameter search\n",
    "- group k fold cross validation for prediction\n",
    "\n",
    "## Several conditions:\n",
    "- (spell corrected and) expanded prompts\n",
    "- raw conversational part\n"
   ],
   "id": "46592c5b8bfa9626"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T12:59:37.468308Z",
     "start_time": "2025-09-18T12:59:37.465532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())\n",
    "device = torch.device(\"cpu\")"
   ],
   "id": "a8f7b5fae4ba0169",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T12:59:37.500611Z",
     "start_time": "2025-09-18T12:59:37.485566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from helpers.normalization import remove_newlines\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn  = sqlite3.connect('../../data/giicg.db')\n",
    "all_prompts = pd.read_sql(\"Select * from expanded_roberta_prompts\", conn)\n",
    "all_prompts['conversational'] = all_prompts['conversational'].apply(remove_newlines)\n",
    "conn.close()"
   ],
   "id": "9e05d29272a8342a",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check data",
   "id": "18235a96570983af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T12:59:37.509665Z",
     "start_time": "2025-09-18T12:59:37.504142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "users_per_gender = all_prompts.groupby('gender')['user_id'].nunique().reset_index(name='num_users')\n",
    "users_per_gender"
   ],
   "id": "880c74c553774e50",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              gender  num_users\n",
       "0    Man (cisgender)         15\n",
       "1  Woman (cisgender)         12"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>num_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T12:59:37.535130Z",
     "start_time": "2025-09-18T12:59:37.531725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages_per_user = all_prompts.groupby('user_id')['message_id'].nunique().reset_index(name='num_messages')\n",
    "messages_per_user"
   ],
   "id": "a47e4e0113a78410",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    user_id  num_messages\n",
       "0         6             9\n",
       "1         8             2\n",
       "2        11            11\n",
       "3        15             3\n",
       "4        16            25\n",
       "5        25             4\n",
       "6        28            22\n",
       "7        31             5\n",
       "8        34            66\n",
       "9        46             5\n",
       "10       47            51\n",
       "11       48            16\n",
       "12       55            36\n",
       "13       56             6\n",
       "14       60             7\n",
       "15       63             2\n",
       "16       65            10\n",
       "17       73            50\n",
       "18       77            20\n",
       "19       79            61\n",
       "20       81             5\n",
       "21       83            15\n",
       "22       88             5\n",
       "23       89            31\n",
       "24       90            14\n",
       "25       91            81\n",
       "26       92             5"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>num_messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>55</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>73</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>77</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>79</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>83</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>89</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>90</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>91</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Combine prompts per user",
   "id": "8d010bdbda245990"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T12:59:37.614495Z",
     "start_time": "2025-09-18T12:59:37.606728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from helpers.normalization import remove_punctuation_and_newlines, remove_capitalization\n",
    "\n",
    "user_prompts = (\n",
    "    all_prompts.groupby(['user_id', 'gender', 'label'])['conversational']\n",
    "    .apply('\\n '.join)\n",
    "    .reset_index()    # Reset index to create a DataFrame\n",
    ")\n",
    "\n",
    "user_prompts.columns = ['user_id', 'gender', 'label', 'combined_prompts']\n",
    "user_prompts = user_prompts[user_prompts['gender'].isin(['Woman (cisgender)', 'Man (cisgender)'])].reset_index()\n",
    "user_prompts"
   ],
   "id": "e9c253dfe6cb4b6d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    index  user_id             gender  label  \\\n",
       "0       0        6    Man (cisgender)      0   \n",
       "1       1        8    Man (cisgender)      0   \n",
       "2       2       11  Woman (cisgender)      1   \n",
       "3       3       15    Man (cisgender)      0   \n",
       "4       4       16  Woman (cisgender)      1   \n",
       "5       5       25    Man (cisgender)      0   \n",
       "6       6       28  Woman (cisgender)      1   \n",
       "7       7       31    Man (cisgender)      0   \n",
       "8       8       34    Man (cisgender)      0   \n",
       "9       9       46    Man (cisgender)      0   \n",
       "10     10       47    Man (cisgender)      0   \n",
       "11     11       48  Woman (cisgender)      1   \n",
       "12     12       55  Woman (cisgender)      1   \n",
       "13     13       56    Man (cisgender)      0   \n",
       "14     14       60  Woman (cisgender)      1   \n",
       "15     15       63  Woman (cisgender)      1   \n",
       "16     16       65  Woman (cisgender)      1   \n",
       "17     17       73  Woman (cisgender)      1   \n",
       "18     18       77    Man (cisgender)      0   \n",
       "19     19       79  Woman (cisgender)      1   \n",
       "20     20       81    Man (cisgender)      0   \n",
       "21     21       83    Man (cisgender)      0   \n",
       "22     22       88    Man (cisgender)      0   \n",
       "23     23       89  Woman (cisgender)      1   \n",
       "24     24       90  Woman (cisgender)      1   \n",
       "25     25       91    Man (cisgender)      0   \n",
       "26     26       92    Man (cisgender)      0   \n",
       "\n",
       "                                     combined_prompts  \n",
       "0   parsing data from python iterator, how it coul...  \n",
       "1        I am working on the problem of reconstruc...  \n",
       "2   Can you adapt the following code so that inste...  \n",
       "3   SET_ALL_TABLES action is currently not fetchin...  \n",
       "4   I want to use Dummy Hot encoding to replace th...  \n",
       "5   what is the best way to encode and compress a ...  \n",
       "6   I have a pandas dataframe like this:  I want t...  \n",
       "7   How can I make use of an ObservableHQDatabaseC...  \n",
       "8   Blender and Python. I have a collection of hun...  \n",
       "9   how to run a Python future without blocking, i...  \n",
       "10  can you create Photoshop Scripts?\\n In which f...  \n",
       "11  hey can you write me a short python script for...  \n",
       "12  write me a script that updates this chart to i...  \n",
       "13  add a short 5-second pause before spinning it ...  \n",
       "14  how can I combine two grib files in jupyter no...  \n",
       "15  can you give me a new code snippet where I jus...  \n",
       "16  I work with Python and have to read an NMEA fi...  \n",
       "17  now it is rounded but there are still zeros pr...  \n",
       "18  I have this function that is supposed to perfo...  \n",
       "19  If a value in t+1 is <0.6 put it to zero but t...  \n",
       "20  I have a programming project and need help: Th...  \n",
       "21  Implement d3-force much closer to the way it i...  \n",
       "22  in my html i have an iframe that is dynamicall...  \n",
       "23  are there paper where these metrics were first...  \n",
       "24  is there a way to get the object key in here?\\...  \n",
       "25  hey, I am writing an application. Because I wa...  \n",
       "26  Please replace my retrieval pipeline here with...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>label</th>\n",
       "      <th>combined_prompts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>0</td>\n",
       "      <td>parsing data from python iterator, how it coul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>0</td>\n",
       "      <td>I am working on the problem of reconstruc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>1</td>\n",
       "      <td>Can you adapt the following code so that inste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>0</td>\n",
       "      <td>SET_ALL_TABLES action is currently not fetchin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>1</td>\n",
       "      <td>I want to use Dummy Hot encoding to replace th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>0</td>\n",
       "      <td>what is the best way to encode and compress a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>1</td>\n",
       "      <td>I have a pandas dataframe like this:  I want t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>0</td>\n",
       "      <td>How can I make use of an ObservableHQDatabaseC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>0</td>\n",
       "      <td>Blender and Python. I have a collection of hun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>0</td>\n",
       "      <td>how to run a Python future without blocking, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>0</td>\n",
       "      <td>can you create Photoshop Scripts?\\n In which f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>1</td>\n",
       "      <td>hey can you write me a short python script for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>55</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>1</td>\n",
       "      <td>write me a script that updates this chart to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>56</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>0</td>\n",
       "      <td>add a short 5-second pause before spinning it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>1</td>\n",
       "      <td>how can I combine two grib files in jupyter no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>63</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>1</td>\n",
       "      <td>can you give me a new code snippet where I jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>65</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>1</td>\n",
       "      <td>I work with Python and have to read an NMEA fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>73</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>1</td>\n",
       "      <td>now it is rounded but there are still zeros pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>77</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>0</td>\n",
       "      <td>I have this function that is supposed to perfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>79</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>1</td>\n",
       "      <td>If a value in t+1 is &lt;0.6 put it to zero but t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>81</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>0</td>\n",
       "      <td>I have a programming project and need help: Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>83</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>0</td>\n",
       "      <td>Implement d3-force much closer to the way it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>88</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>0</td>\n",
       "      <td>in my html i have an iframe that is dynamicall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>89</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>1</td>\n",
       "      <td>are there paper where these metrics were first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>90</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>1</td>\n",
       "      <td>is there a way to get the object key in here?\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>91</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>0</td>\n",
       "      <td>hey, I am writing an application. Because I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>92</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>0</td>\n",
       "      <td>Please replace my retrieval pipeline here with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T12:59:37.643052Z",
     "start_time": "2025-09-18T12:59:37.639876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(user_prompts[['combined_prompts', 'label']].head())\n",
    "print(user_prompts[['combined_prompts']].nunique())\n"
   ],
   "id": "6dd2ee10a645a287",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    combined_prompts  label\n",
      "0  parsing data from python iterator, how it coul...      0\n",
      "1       I am working on the problem of reconstruc...      0\n",
      "2  Can you adapt the following code so that inste...      1\n",
      "3  SET_ALL_TABLES action is currently not fetchin...      0\n",
      "4  I want to use Dummy Hot encoding to replace th...      1\n",
      "combined_prompts    27\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T12:59:37.678866Z",
     "start_time": "2025-09-18T12:59:37.676972Z"
    }
   },
   "cell_type": "code",
   "source": "print(user_prompts['label'].dtype)\n",
   "id": "71878248f64f5e64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Set up Model",
   "id": "48aa2574a5022f2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T12:59:38.294519Z",
     "start_time": "2025-09-18T12:59:37.695095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from transformers import DataCollatorWithPadding\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "with open(\"finetune/label2id.json\", \"r\") as f:\n",
    "    label2id = json.load(f)\n",
    "\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "num_labels = len(label2id)\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    hidden_dropout_prob=0.3,        # Increase from 0.1 to 0.3+\n",
    "    attention_probs_dropout_prob=0.3\n",
    ")\n",
    "\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=num_labels\n",
    "    )\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"combined_prompts\"],\n",
    "        truncation=True,\n",
    "        max_length=512, # trncate to max sample size to avoid index errors\n",
    "        padding=False # padding is handled in the data collator\n",
    "    )\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    precision = precision_score(labels, preds, average='weighted')\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ],
   "id": "d6f2df1d55b4931e",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check max sample size",
   "id": "3ea34a448fc47f2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T12:59:38.315672Z",
     "start_time": "2025-09-18T12:59:38.299838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "texts = user_prompts['combined_prompts'].tolist()\n",
    "\n",
    "token_counts = [len(tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=512)) for text in texts]\n",
    "\n",
    "max_tokens = max(token_counts)\n",
    "min_tokens = min(token_counts)\n",
    "avg_tokens = sum(token_counts) / len(token_counts)\n",
    "\n",
    "print(f\"Max tokens: {max_tokens}\")\n",
    "print(f\"Min tokens: {min_tokens}\")\n"
   ],
   "id": "5f3bbf2e1e54be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tokens: 512\n",
      "Min tokens: 34\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Cross Validation\n",
    "\n",
    "- selected hyperparameters: lr 3.2e-5, batchsizes 8, epochs 5"
   ],
   "id": "d022f15a4f430b17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T12:59:51.079534Z",
     "start_time": "2025-09-18T12:59:38.322820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from datasets import Dataset\n",
    "\n",
    "texts = user_prompts['combined_prompts'].tolist()\n",
    "labels = user_prompts['label'].tolist()\n",
    "n_splits = 5  # e.g. 5-fold CV\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(texts, labels)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "\n",
    "    train_prompts = user_prompts.iloc[train_idx]\n",
    "    val_prompts = user_prompts.iloc[val_idx]\n",
    "    print(\"train prompts: \", train_prompts)\n",
    "    print(\"val prompts: \",val_prompts)\n",
    "\n",
    "    train_dataset = Dataset.from_pandas(train_prompts[['combined_prompts', 'label']])\n",
    "    val_dataset = Dataset.from_pandas(val_prompts[['combined_prompts', 'label']])\n",
    "\n",
    "    train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "    val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    print(\"  Train label counts:\", train_prompts['label'].value_counts().to_dict())\n",
    "    print(\"  Val   label counts:\", val_prompts['label'].value_counts().to_dict())\n",
    "\n",
    "    # Set up Trainer with model/tokenizer/data_collator as before\n",
    "    trainer = Trainer(\n",
    "        model_init=model_init,\n",
    "        args=TrainingArguments(\n",
    "            output_dir=f\"./finetune/cross_validation/run_1/fold_{fold+1}_results\",\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            logging_dir=f\"./fold_{fold+1}_logs\",\n",
    "            per_device_train_batch_size=8,\n",
    "            per_device_eval_batch_size=8,\n",
    "            num_train_epochs=5,\n",
    "            learning_rate=1e-5,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            logging_steps=1,\n",
    "            logging_strategy=\"steps\",\n",
    "            weight_decay=0.05,\n",
    "        ),\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_metrics = trainer.evaluate()\n",
    "    print(f\"Fold {fold + 1} metrics:\", eval_metrics)\n",
    "    all_results.append(eval_metrics)\n",
    "\n",
    "print(all_results)\n",
    "\n",
    "\n"
   ],
   "id": "62fcd184b881bd15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "train prompts:      index  user_id             gender  label  \\\n",
      "0       0        6    Man (cisgender)      0   \n",
      "1       1        8    Man (cisgender)      0   \n",
      "2       2       11  Woman (cisgender)      1   \n",
      "4       4       16  Woman (cisgender)      1   \n",
      "5       5       25    Man (cisgender)      0   \n",
      "7       7       31    Man (cisgender)      0   \n",
      "8       8       34    Man (cisgender)      0   \n",
      "11     11       48  Woman (cisgender)      1   \n",
      "12     12       55  Woman (cisgender)      1   \n",
      "13     13       56    Man (cisgender)      0   \n",
      "14     14       60  Woman (cisgender)      1   \n",
      "16     16       65  Woman (cisgender)      1   \n",
      "17     17       73  Woman (cisgender)      1   \n",
      "18     18       77    Man (cisgender)      0   \n",
      "20     20       81    Man (cisgender)      0   \n",
      "21     21       83    Man (cisgender)      0   \n",
      "22     22       88    Man (cisgender)      0   \n",
      "23     23       89  Woman (cisgender)      1   \n",
      "24     24       90  Woman (cisgender)      1   \n",
      "25     25       91    Man (cisgender)      0   \n",
      "26     26       92    Man (cisgender)      0   \n",
      "\n",
      "                                     combined_prompts  \n",
      "0   parsing data from python iterator, how it coul...  \n",
      "1        I am working on the problem of reconstruc...  \n",
      "2   Can you adapt the following code so that inste...  \n",
      "4   I want to use Dummy Hot encoding to replace th...  \n",
      "5   what is the best way to encode and compress a ...  \n",
      "7   How can I make use of an ObservableHQDatabaseC...  \n",
      "8   Blender and Python. I have a collection of hun...  \n",
      "11  hey can you write me a short python script for...  \n",
      "12  write me a script that updates this chart to i...  \n",
      "13  add a short 5-second pause before spinning it ...  \n",
      "14  how can I combine two grib files in jupyter no...  \n",
      "16  I work with Python and have to read an NMEA fi...  \n",
      "17  now it is rounded but there are still zeros pr...  \n",
      "18  I have this function that is supposed to perfo...  \n",
      "20  I have a programming project and need help: Th...  \n",
      "21  Implement d3-force much closer to the way it i...  \n",
      "22  in my html i have an iframe that is dynamicall...  \n",
      "23  are there paper where these metrics were first...  \n",
      "24  is there a way to get the object key in here?\\...  \n",
      "25  hey, I am writing an application. Because I wa...  \n",
      "26  Please replace my retrieval pipeline here with...  \n",
      "val prompts:      index  user_id             gender  label  \\\n",
      "3       3       15    Man (cisgender)      0   \n",
      "6       6       28  Woman (cisgender)      1   \n",
      "9       9       46    Man (cisgender)      0   \n",
      "10     10       47    Man (cisgender)      0   \n",
      "15     15       63  Woman (cisgender)      1   \n",
      "19     19       79  Woman (cisgender)      1   \n",
      "\n",
      "                                     combined_prompts  \n",
      "3   SET_ALL_TABLES action is currently not fetchin...  \n",
      "6   I have a pandas dataframe like this:  I want t...  \n",
      "9   how to run a Python future without blocking, i...  \n",
      "10  can you create Photoshop Scripts?\\n In which f...  \n",
      "15  can you give me a new code snippet where I jus...  \n",
      "19  If a value in t+1 is <0.6 put it to zero but t...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 21/21 [00:00<00:00, 3603.94 examples/s]\n",
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1680.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train label counts: {0: 12, 1: 9}\n",
      "  Val   label counts: {0: 3, 1: 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/_h/dm14sczn7s77lrr765t54y7h0000gn/T/ipykernel_65265/2094714821.py:33: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/15 00:09 < 00:05, 0.86 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.659900</td>\n",
       "      <td>0.696399</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.713000</td>\n",
       "      <td>0.696399</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "ef8c67fa83744e8fa1ff9bb98f401169"
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG16XFamilyCommandBuffer: 0x15b4ab0e0>\n",
      "    label = <none> \n",
      "    device = <AGXG16SDevice: 0x1098f5200>\n",
      "        name = Apple M4 Pro \n",
      "    commandQueue = <AGXG16XFamilyCommandQueue: 0x105179400>\n",
      "        label = <none> \n",
      "        device = <AGXG16SDevice: 0x1098f5200>\n",
      "            name = Apple M4 Pro \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG16XFamilyCommandBuffer: 0x15c326ad0>\n",
      "    label = <none> \n",
      "    device = <AGXG16SDevice: 0x1098f5200>\n",
      "        name = Apple M4 Pro \n",
      "    commandQueue = <AGXG16XFamilyCommandQueue: 0x105179400>\n",
      "        label = <none> \n",
      "        device = <AGXG16SDevice: 0x1098f5200>\n",
      "            name = Apple M4 Pro \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG16XFamilyCommandBuffer: 0x30c12e7d0>\n",
      "    label = <none> \n",
      "    device = <AGXG16SDevice: 0x1098f5200>\n",
      "        name = Apple M4 Pro \n",
      "    commandQueue = <AGXG16XFamilyCommandQueue: 0x105179400>\n",
      "        label = <none> \n",
      "        device = <AGXG16SDevice: 0x1098f5200>\n",
      "            name = Apple M4 Pro \n",
      "    retainedReferences = 1\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG16XFamilyCommandBuffer: 0x30bd24460>\n",
      "    label = <none> \n",
      "    device = <AGXG16SDevice: 0x1098f5200>\n",
      "        name = Apple M4 Pro \n",
      "    commandQueue = <AGXG16XFamilyCommandQueue: 0x105179400>\n",
      "        label = <none> \n",
      "        device = <AGXG16SDevice: 0x1098f5200>\n",
      "            name = Apple M4 Pro \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG16XFamilyCommandBuffer: 0x30bf3ce40>\n",
      "    label = <none> \n",
      "    device = <AGXG16SDevice: 0x1098f5200>\n",
      "        name = Apple M4 Pro \n",
      "    commandQueue = <AGXG16XFamilyCommandQueue: 0x105179400>\n",
      "        label = <none> \n",
      "        device = <AGXG16SDevice: 0x1098f5200>\n",
      "            name = Apple M4 Pro \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG16XFamilyCommandBuffer: 0x30b29d450>\n",
      "    label = <none> \n",
      "    device = <AGXG16SDevice: 0x1098f5200>\n",
      "        name = Apple M4 Pro \n",
      "    commandQueue = <AGXG16XFamilyCommandQueue: 0x105179400>\n",
      "        label = <none> \n",
      "        device = <AGXG16SDevice: 0x1098f5200>\n",
      "            name = Apple M4 Pro \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[47]\u001B[39m\u001B[32m, line 58\u001B[39m\n\u001B[32m     32\u001B[39m \u001B[38;5;66;03m# Set up Trainer with model/tokenizer/data_collator as before\u001B[39;00m\n\u001B[32m     33\u001B[39m trainer = Trainer(\n\u001B[32m     34\u001B[39m     model_init=model_init,\n\u001B[32m     35\u001B[39m     args=TrainingArguments(\n\u001B[32m   (...)\u001B[39m\u001B[32m     55\u001B[39m     compute_metrics=compute_metrics,\n\u001B[32m     56\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m58\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     59\u001B[39m eval_metrics = trainer.evaluate()\n\u001B[32m     60\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFold \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfold\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m metrics:\u001B[39m\u001B[33m\"\u001B[39m, eval_metrics)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/trainer.py:2328\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   2326\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   2327\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2328\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2329\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2330\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2331\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2332\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2333\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/trainer.py:2788\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   2785\u001B[39m     \u001B[38;5;28mself\u001B[39m.control.should_training_stop = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m   2787\u001B[39m \u001B[38;5;28mself\u001B[39m.control = \u001B[38;5;28mself\u001B[39m.callback_handler.on_epoch_end(args, \u001B[38;5;28mself\u001B[39m.state, \u001B[38;5;28mself\u001B[39m.control)\n\u001B[32m-> \u001B[39m\u001B[32m2788\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_maybe_log_save_evaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2789\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtr_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_norm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_time\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlearning_rate\u001B[49m\n\u001B[32m   2790\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2792\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m DebugOption.TPU_METRICS_DEBUG \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.debug:\n\u001B[32m   2793\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m is_torch_xla_available():\n\u001B[32m   2794\u001B[39m         \u001B[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/trainer.py:3227\u001B[39m, in \u001B[36mTrainer._maybe_log_save_evaluate\u001B[39m\u001B[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001B[39m\n\u001B[32m   3225\u001B[39m metrics = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   3226\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.control.should_evaluate:\n\u001B[32m-> \u001B[39m\u001B[32m3227\u001B[39m     metrics = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3228\u001B[39m     is_new_best_metric = \u001B[38;5;28mself\u001B[39m._determine_best_metric(metrics=metrics, trial=trial)\n\u001B[32m   3230\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.save_strategy == SaveStrategy.BEST:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/trainer.py:3176\u001B[39m, in \u001B[36mTrainer._evaluate\u001B[39m\u001B[34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001B[39m\n\u001B[32m   3175\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_evaluate\u001B[39m(\u001B[38;5;28mself\u001B[39m, trial, ignore_keys_for_eval, skip_scheduler=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m-> \u001B[39m\u001B[32m3176\u001B[39m     metrics = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3177\u001B[39m     \u001B[38;5;28mself\u001B[39m._report_to_hp_search(trial, \u001B[38;5;28mself\u001B[39m.state.global_step, metrics)\n\u001B[32m   3179\u001B[39m     \u001B[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/trainer.py:4469\u001B[39m, in \u001B[36mTrainer.evaluate\u001B[39m\u001B[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[39m\n\u001B[32m   4466\u001B[39m start_time = time.time()\n\u001B[32m   4468\u001B[39m eval_loop = \u001B[38;5;28mself\u001B[39m.prediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.use_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.evaluation_loop\n\u001B[32m-> \u001B[39m\u001B[32m4469\u001B[39m output = \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4470\u001B[39m \u001B[43m    \u001B[49m\u001B[43meval_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4471\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mEvaluation\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   4472\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001B[39;49;00m\n\u001B[32m   4473\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# self.args.prediction_loss_only\u001B[39;49;00m\n\u001B[32m   4474\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   4475\u001B[39m \u001B[43m    \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4476\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4477\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4479\u001B[39m total_batch_size = \u001B[38;5;28mself\u001B[39m.args.eval_batch_size * \u001B[38;5;28mself\u001B[39m.args.world_size\n\u001B[32m   4480\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_jit_compilation_time\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output.metrics:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/trainer.py:4687\u001B[39m, in \u001B[36mTrainer.evaluation_loop\u001B[39m\u001B[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[39m\n\u001B[32m   4685\u001B[39m     labels = \u001B[38;5;28mself\u001B[39m.accelerator.pad_across_processes(labels, dim=\u001B[32m1\u001B[39m, pad_index=-\u001B[32m100\u001B[39m)\n\u001B[32m   4686\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m logits \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m4687\u001B[39m     logits = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43maccelerator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpad_across_processes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad_index\u001B[49m\u001B[43m=\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   4688\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.preprocess_logits_for_metrics \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   4689\u001B[39m         logits = \u001B[38;5;28mself\u001B[39m.preprocess_logits_for_metrics(logits, labels)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/accelerate/accelerator.py:3094\u001B[39m, in \u001B[36mAccelerator.pad_across_processes\u001B[39m\u001B[34m(self, tensor, dim, pad_index, pad_first)\u001B[39m\n\u001B[32m   3061\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpad_across_processes\u001B[39m(\u001B[38;5;28mself\u001B[39m, tensor, dim=\u001B[32m0\u001B[39m, pad_index=\u001B[32m0\u001B[39m, pad_first=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m   3062\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   3063\u001B[39m \u001B[33;03m    Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so\u001B[39;00m\n\u001B[32m   3064\u001B[39m \u001B[33;03m    they can safely be gathered.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   3092\u001B[39m \u001B[33;03m    ```\u001B[39;00m\n\u001B[32m   3093\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m3094\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpad_across_processes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad_index\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpad_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad_first\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpad_first\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/accelerate/utils/operations.py:407\u001B[39m, in \u001B[36mchained_operation.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    404\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(function)\n\u001B[32m    405\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapper\u001B[39m(*args, **kwargs):\n\u001B[32m    406\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m407\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    408\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m DistributedOperationException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    409\u001B[39m         operation = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunction.\u001B[34m__module__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunction.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/accelerate/utils/operations.py:677\u001B[39m, in \u001B[36mpad_across_processes\u001B[39m\u001B[34m(tensor, dim, pad_index, pad_first)\u001B[39m\n\u001B[32m    674\u001B[39m     new_tensor[indices] = tensor\n\u001B[32m    675\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m new_tensor\n\u001B[32m--> \u001B[39m\u001B[32m677\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrecursively_apply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    678\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_pad_across_processes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror_on_other_type\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad_index\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpad_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad_first\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpad_first\u001B[49m\n\u001B[32m    679\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/accelerate/utils/operations.py:126\u001B[39m, in \u001B[36mrecursively_apply\u001B[39m\u001B[34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001B[39m\n\u001B[32m    117\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(data)(\n\u001B[32m    118\u001B[39m         {\n\u001B[32m    119\u001B[39m             k: recursively_apply(\n\u001B[32m   (...)\u001B[39m\u001B[32m    123\u001B[39m         }\n\u001B[32m    124\u001B[39m     )\n\u001B[32m    125\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m test_type(data):\n\u001B[32m--> \u001B[39m\u001B[32m126\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    127\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m error_on_other_type:\n\u001B[32m    128\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[32m    129\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mUnsupported types (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(data)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m) passed to `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m`. Only nested list/tuple/dicts of \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    130\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mobjects that are valid for `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_type.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m` should be passed.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    131\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/accelerate/utils/operations.py:657\u001B[39m, in \u001B[36mpad_across_processes.<locals>._pad_across_processes\u001B[39m\u001B[34m(tensor, dim, pad_index, pad_first)\u001B[39m\n\u001B[32m    654\u001B[39m     dim += \u001B[38;5;28mlen\u001B[39m(tensor.shape)\n\u001B[32m    656\u001B[39m \u001B[38;5;66;03m# Gather all sizes\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m657\u001B[39m size = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;28;01mNone\u001B[39;00m]\n\u001B[32m    658\u001B[39m sizes = gather(size).cpu()\n\u001B[32m    659\u001B[39m \u001B[38;5;66;03m# Then pad to the maximum size\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "results = pd.DataFrame(all_results)\n",
    "stats = results.describe()\n",
    "with open(\"roberta_per_user_stats.tex\", \"w\") as f:\n",
    "    stats.to_latex(f)\n"
   ],
   "id": "77094a3aa91a0362"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "stats",
   "id": "2e4552666d0eec03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trainer.save_model(\"finetune/best_model_per_user\")",
   "id": "52f5ae665633c1b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5011e71f351d1c6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "few = user_prompts.sample(8, random_state=42)\n",
    "train_ds = Dataset.from_pandas(few[['combined_prompts', 'label']])\n",
    "train_ds = train_ds.map(tokenize_function, batched=True)\n",
    "trainer = Trainer(\n",
    "    model=model_init(),\n",
    "    args=TrainingArguments(output_dir=\"./tmp\", per_device_train_batch_size=2, num_train_epochs=30, logging_steps=1),\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=train_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()\n",
    "print(trainer.evaluate())"
   ],
   "id": "28d596f213dae8cf"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
