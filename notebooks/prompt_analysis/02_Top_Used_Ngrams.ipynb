{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Top Used Words\n",
    "use expanded, decapitalited and punctuation removed prompts\n",
    "- concatenate all prompts from all conversations per user\n",
    "- then count frequencies per user\n",
    "- normalize by total token count\n",
    "- fuse counts within each gender group\n",
    "- take top 10 or 15 words\n",
    "- logistic regression or chi square to find most discriminative word\n"
   ],
   "id": "b3c193ea9e3cda79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:58:23.462480Z",
     "start_time": "2025-10-10T12:58:23.411796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('../../data/giicg.db')\n",
    "\n",
    "prompts = pd.read_sql(\"SELECT * FROM expanded_prompts\", conn)\n"
   ],
   "id": "ce9881ee907a0306",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:58:23.475357Z",
     "start_time": "2025-10-10T12:58:23.469582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from helpers.normalization import remove_punctuation_and_newlines, remove_capitalization\n",
    "\n",
    "prompts['conversational'] = prompts['conversational'].apply(remove_punctuation_and_newlines)\n",
    "prompts['conversational'] = prompts['conversational'].apply(remove_capitalization)"
   ],
   "id": "d21a05434211b214",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Concatenate all prompts per user",
   "id": "1f30356561163092"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:58:23.789737Z",
     "start_time": "2025-10-10T12:58:23.785438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_prompts = (\n",
    "    prompts.groupby(['user_id', 'gender'])['conversational']\n",
    "    .apply(' '.join)\n",
    "    .reset_index()    # Reset index to create a DataFrame\n",
    ")\n",
    "\n",
    "user_prompts.columns = ['user_id', 'gender', 'combined_prompts']\n",
    "user_prompts = user_prompts[user_prompts['gender'].isin(['Woman (cisgender)', 'Man (cisgender)'])].reset_index()"
   ],
   "id": "84fd2bbec744c906",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Count Uni and Bi grams",
   "id": "39b4d2fd2a3c77f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:58:24.804716Z",
     "start_time": "2025-10-10T12:58:23.840317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_unigrams = CountVectorizer()\n",
    "vectorizer_bigrams = CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "unigram_matrix = vectorizer_unigrams.fit_transform(user_prompts['combined_prompts'])\n",
    "words = vectorizer_unigrams.get_feature_names_out()\n",
    "unigram_df = pd.DataFrame(unigram_matrix.toarray(), columns=words)\n",
    "unigram_df['user_id'] = user_prompts['user_id'].values\n",
    "unigram_df['gender'] = user_prompts['gender'].values\n",
    "\n",
    "bigram_matrix = vectorizer_bigrams.fit_transform(user_prompts['combined_prompts'])\n",
    "bigrams = vectorizer_bigrams.get_feature_names_out()\n",
    "bigram_fd = pd.DataFrame(bigram_matrix.toarray(), columns=bigrams)\n",
    "bigram_fd['user_id'] = user_prompts['user_id'].values\n",
    "bigram_fd['gender'] = user_prompts['gender'].values\n",
    "\n",
    "# 1. Normalize counts per user (row) by their total word count\n",
    "word_cols = words  # all column names for words\n",
    "user_totals = unigram_df[word_cols].sum(axis=1)\n",
    "unigram_df[word_cols] = unigram_df[word_cols].div(user_totals, axis=0)\n",
    "\n",
    "bigram_cols = bigrams  # all column names for words\n",
    "user_totals = bigram_fd[bigram_cols].sum(axis=1)\n",
    "bigram_fd[bigram_cols] = bigram_fd[bigram_cols].div(user_totals, axis=0)\n",
    "\n",
    "# 2. Compute the mean vector per gender (i.e., average normalized word frequencies)\n",
    "gender_unigrams = unigram_df.groupby('gender')[word_cols].mean()\n",
    "gender_bigrams = bigram_fd.groupby('gender')[bigram_cols].mean()\n"
   ],
   "id": "2046a75dab4518b8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:58:24.903181Z",
     "start_time": "2025-10-10T12:58:24.876696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "N = 10\n",
    "female_uni = gender_unigrams.loc['Woman (cisgender)'].sort_values(ascending=False).head(N).reset_index()\n",
    "male_uni = gender_unigrams.loc['Man (cisgender)'].sort_values(ascending=False).head(N).reset_index()\n",
    "female_uni.columns = ['word_f', 'freq_f']\n",
    "male_uni.columns = ['word_m', 'freq_m']\n",
    "\n",
    "female_bi= gender_bigrams.loc['Woman (cisgender)'].sort_values(ascending=False).head(N).reset_index()\n",
    "male_bi = gender_bigrams.loc['Man (cisgender)'].sort_values(ascending=False).head(N).reset_index()\n",
    "female_bi.columns = ['bigr_f', 'bi_freq_f']\n",
    "male_bi.columns = ['bigr_m', 'bi_freq_m']\n",
    "\n",
    "\n",
    "combined_df = pd.concat([male_uni, male_bi, female_uni, female_bi], axis=1)\n",
    "combined_df.to_latex(\"most_used_n_grams.tex\", float_format=\"%.4f\", header=[\"Word\", \"Freq.\", \"Bigram\", \"Freq.\", \"Word\", \"Freq.\" , \"Bigram\", \"Freq.\"])\n",
    "combined_df\n"
   ],
   "id": "36412d54242de4df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  word_m    freq_m   bigr_m  bi_freq_m word_f    freq_f             bigr_f  \\\n",
       "0    the  0.074242   of the   0.005596    the  0.067518            can you   \n",
       "1     to  0.034931   in the   0.005528     to  0.031762            want to   \n",
       "2     is  0.029539   at the   0.005458    and  0.025825             of the   \n",
       "3     of  0.027270  how can   0.005372    can  0.021263           the same   \n",
       "4     in  0.018219   on the   0.004774    you  0.017356             in the   \n",
       "5    and  0.017033   is the   0.004667     of  0.016486            give me   \n",
       "6     it  0.014231   to the   0.003846     in  0.015971            how can   \n",
       "7   that  0.013940  need to   0.003581   this  0.014460           you give   \n",
       "8    how  0.013723  what is   0.003489   code  0.014315  judgment balanced   \n",
       "9   this  0.011637  want to   0.003239     is  0.013461           have the   \n",
       "\n",
       "   bi_freq_f  \n",
       "0   0.013407  \n",
       "1   0.008138  \n",
       "2   0.006636  \n",
       "3   0.005318  \n",
       "4   0.005018  \n",
       "5   0.004940  \n",
       "6   0.004778  \n",
       "7   0.004520  \n",
       "8   0.004049  \n",
       "9   0.003865  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_m</th>\n",
       "      <th>freq_m</th>\n",
       "      <th>bigr_m</th>\n",
       "      <th>bi_freq_m</th>\n",
       "      <th>word_f</th>\n",
       "      <th>freq_f</th>\n",
       "      <th>bigr_f</th>\n",
       "      <th>bi_freq_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>0.074242</td>\n",
       "      <td>of the</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>the</td>\n",
       "      <td>0.067518</td>\n",
       "      <td>can you</td>\n",
       "      <td>0.013407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>0.034931</td>\n",
       "      <td>in the</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>to</td>\n",
       "      <td>0.031762</td>\n",
       "      <td>want to</td>\n",
       "      <td>0.008138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>0.029539</td>\n",
       "      <td>at the</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>and</td>\n",
       "      <td>0.025825</td>\n",
       "      <td>of the</td>\n",
       "      <td>0.006636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>0.027270</td>\n",
       "      <td>how can</td>\n",
       "      <td>0.005372</td>\n",
       "      <td>can</td>\n",
       "      <td>0.021263</td>\n",
       "      <td>the same</td>\n",
       "      <td>0.005318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in</td>\n",
       "      <td>0.018219</td>\n",
       "      <td>on the</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>you</td>\n",
       "      <td>0.017356</td>\n",
       "      <td>in the</td>\n",
       "      <td>0.005018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>and</td>\n",
       "      <td>0.017033</td>\n",
       "      <td>is the</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>of</td>\n",
       "      <td>0.016486</td>\n",
       "      <td>give me</td>\n",
       "      <td>0.004940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it</td>\n",
       "      <td>0.014231</td>\n",
       "      <td>to the</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>in</td>\n",
       "      <td>0.015971</td>\n",
       "      <td>how can</td>\n",
       "      <td>0.004778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>that</td>\n",
       "      <td>0.013940</td>\n",
       "      <td>need to</td>\n",
       "      <td>0.003581</td>\n",
       "      <td>this</td>\n",
       "      <td>0.014460</td>\n",
       "      <td>you give</td>\n",
       "      <td>0.004520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>how</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>what is</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>code</td>\n",
       "      <td>0.014315</td>\n",
       "      <td>judgment balanced</td>\n",
       "      <td>0.004049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>this</td>\n",
       "      <td>0.011637</td>\n",
       "      <td>want to</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>is</td>\n",
       "      <td>0.013461</td>\n",
       "      <td>have the</td>\n",
       "      <td>0.003865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
