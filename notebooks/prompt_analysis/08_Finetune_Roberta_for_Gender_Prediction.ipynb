{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Fine Tune\n",
    "- RoBERTa\n",
    "- No need for inference speed up using distil bert since dataset is very small\n",
    "- Hyperparameter tuning using huggingfaces hyperparameter search\n",
    "- group k fold cross validation for prediction\n",
    "\n",
    "## Several conditions:\n",
    "- (spell corrected and) expanded prompts\n",
    "- raw conversational part\n"
   ],
   "id": "92df0da8972ba415"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T11:18:00.446076Z",
     "start_time": "2025-09-13T11:18:00.443752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ],
   "id": "26b5640ab14c7350",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T11:18:02.947310Z",
     "start_time": "2025-09-13T11:18:02.938945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn  = sqlite3.connect('../../giicg.db')\n",
    "all_prompts = pd.read_sql(\"Select * from expanded_prompts\", conn)\n",
    "conn.close()\n",
    "all_prompts"
   ],
   "id": "134310018dd52364",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     message_id  conversation_id  role  \\\n",
       "0             1                1  user   \n",
       "1           730               32  user   \n",
       "2          1133               55  user   \n",
       "3          1135               55  user   \n",
       "4          1137               55  user   \n",
       "..          ...              ...   ...   \n",
       "748        1131               54  user   \n",
       "749        1532               71  user   \n",
       "750        1646               82  user   \n",
       "751        1849                2  user   \n",
       "752        1851                2  user   \n",
       "\n",
       "                                          message_text  \\\n",
       "0    parsing data from python iterator, how it coul...   \n",
       "1    Write python function to do operations with in...   \n",
       "2    Write shortest tutorial on creating RAG on ema...   \n",
       "3                                        what is FAISS   \n",
       "4     Transform given code to process large .mbox file   \n",
       "..                                                 ...   \n",
       "748  import pandas as pd\\nimport numpy as np\\nfrom ...   \n",
       "749  from transformers import AutoTokenizer, AutoMo...   \n",
       "750  def run_query(query, n_results):\\n    query_em...   \n",
       "751  \\n    I am working on the problem of reconstru...   \n",
       "752  \\n        Focus on one step at the time. Write...   \n",
       "\n",
       "                                        conversational  \\\n",
       "0    parsing data from python iterator, how it coul...   \n",
       "1    Write python function to do operations with in...   \n",
       "2    Write shortest tutorial on creating RAG on ema...   \n",
       "3                                        what is FAISS   \n",
       "4     Transform given code to process large .mbox file   \n",
       "..                                                 ...   \n",
       "748  I want to tune optimal thresholds. Currently, ...   \n",
       "749  I want to use an LLM for listwise reranking in...   \n",
       "750  this is my code. I want to: Get nodes and edge...   \n",
       "751  \\n    I am working on the problem of reconstru...   \n",
       "752  Focus on one step at the time. Write what is t...   \n",
       "\n",
       "                                                  code  \\\n",
       "0                                                        \n",
       "1                                                        \n",
       "2                                                        \n",
       "3                                                        \n",
       "4                                                        \n",
       "..                                                 ...   \n",
       "748  import pandas as pd\\nimport numpy as np\\nfrom ...   \n",
       "749  from transformers import AutoTokenizer, AutoMo...   \n",
       "750  def run_query(query, n_results):\\n    query_em...   \n",
       "751                                                      \n",
       "752                                                      \n",
       "\n",
       "                                                 other           gender  \\\n",
       "0                                                       Man (cisgender)   \n",
       "1    report_dt\\tsource\\tmetric_name\\tmetric_num\\tme...  Man (cisgender)   \n",
       "2                                                       Man (cisgender)   \n",
       "3                                                       Man (cisgender)   \n",
       "4     Transform given code to process large .mbox file  Man (cisgender)   \n",
       "..                                                 ...              ...   \n",
       "748  The narratives list looks like this:\\nnarrativ...  Man (cisgender)   \n",
       "749                                                     Man (cisgender)   \n",
       "750                                                     Man (cisgender)   \n",
       "751  Classic CV - Drone navigation\\nIf you ever tho...  Man (cisgender)   \n",
       "752                                                     Man (cisgender)   \n",
       "\n",
       "     user_id language  \n",
       "0          6       en  \n",
       "1          6       en  \n",
       "2          6       en  \n",
       "3          6       en  \n",
       "4          6       en  \n",
       "..       ...      ...  \n",
       "748       92       en  \n",
       "749       92       en  \n",
       "750       92       en  \n",
       "751        8       en  \n",
       "752        8       en  \n",
       "\n",
       "[753 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>role</th>\n",
       "      <th>message_text</th>\n",
       "      <th>conversational</th>\n",
       "      <th>code</th>\n",
       "      <th>other</th>\n",
       "      <th>gender</th>\n",
       "      <th>user_id</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>parsing data from python iterator, how it coul...</td>\n",
       "      <td>parsing data from python iterator, how it coul...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>730</td>\n",
       "      <td>32</td>\n",
       "      <td>user</td>\n",
       "      <td>Write python function to do operations with in...</td>\n",
       "      <td>Write python function to do operations with in...</td>\n",
       "      <td></td>\n",
       "      <td>report_dt\\tsource\\tmetric_name\\tmetric_num\\tme...</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1133</td>\n",
       "      <td>55</td>\n",
       "      <td>user</td>\n",
       "      <td>Write shortest tutorial on creating RAG on ema...</td>\n",
       "      <td>Write shortest tutorial on creating RAG on ema...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1135</td>\n",
       "      <td>55</td>\n",
       "      <td>user</td>\n",
       "      <td>what is FAISS</td>\n",
       "      <td>what is FAISS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1137</td>\n",
       "      <td>55</td>\n",
       "      <td>user</td>\n",
       "      <td>Transform given code to process large .mbox file</td>\n",
       "      <td>Transform given code to process large .mbox file</td>\n",
       "      <td></td>\n",
       "      <td>Transform given code to process large .mbox file</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>1131</td>\n",
       "      <td>54</td>\n",
       "      <td>user</td>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nfrom ...</td>\n",
       "      <td>I want to tune optimal thresholds. Currently, ...</td>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nfrom ...</td>\n",
       "      <td>The narratives list looks like this:\\nnarrativ...</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>92</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>1532</td>\n",
       "      <td>71</td>\n",
       "      <td>user</td>\n",
       "      <td>from transformers import AutoTokenizer, AutoMo...</td>\n",
       "      <td>I want to use an LLM for listwise reranking in...</td>\n",
       "      <td>from transformers import AutoTokenizer, AutoMo...</td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>92</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>1646</td>\n",
       "      <td>82</td>\n",
       "      <td>user</td>\n",
       "      <td>def run_query(query, n_results):\\n    query_em...</td>\n",
       "      <td>this is my code. I want to: Get nodes and edge...</td>\n",
       "      <td>def run_query(query, n_results):\\n    query_em...</td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>92</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1849</td>\n",
       "      <td>2</td>\n",
       "      <td>user</td>\n",
       "      <td>\\n    I am working on the problem of reconstru...</td>\n",
       "      <td>\\n    I am working on the problem of reconstru...</td>\n",
       "      <td></td>\n",
       "      <td>Classic CV - Drone navigation\\nIf you ever tho...</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>8</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>1851</td>\n",
       "      <td>2</td>\n",
       "      <td>user</td>\n",
       "      <td>\\n        Focus on one step at the time. Write...</td>\n",
       "      <td>Focus on one step at the time. Write what is t...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>8</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>753 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Filter and clean",
   "id": "c79c7fee0996934d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T11:18:05.107363Z",
     "start_time": "2025-09-13T11:18:05.100510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from helpers.normalization import remove_newlines\n",
    "\n",
    "all_prompts = all_prompts[all_prompts['gender'].isin(['Woman (cisgender)', 'Man (cisgender)'])].reset_index()\n",
    "all_prompts['conversational']  = all_prompts['conversational'].apply(remove_newlines)\n",
    "all_prompts"
   ],
   "id": "46bb067c87538e5c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     index  message_id  conversation_id  role  \\\n",
       "0        0           1                1  user   \n",
       "1        1         730               32  user   \n",
       "2        2        1133               55  user   \n",
       "3        3        1135               55  user   \n",
       "4        4        1137               55  user   \n",
       "..     ...         ...              ...   ...   \n",
       "741    748        1131               54  user   \n",
       "742    749        1532               71  user   \n",
       "743    750        1646               82  user   \n",
       "744    751        1849                2  user   \n",
       "745    752        1851                2  user   \n",
       "\n",
       "                                          message_text  \\\n",
       "0    parsing data from python iterator, how it coul...   \n",
       "1    Write python function to do operations with in...   \n",
       "2    Write shortest tutorial on creating RAG on ema...   \n",
       "3                                        what is FAISS   \n",
       "4     Transform given code to process large .mbox file   \n",
       "..                                                 ...   \n",
       "741  import pandas as pd\\nimport numpy as np\\nfrom ...   \n",
       "742  from transformers import AutoTokenizer, AutoMo...   \n",
       "743  def run_query(query, n_results):\\n    query_em...   \n",
       "744  \\n    I am working on the problem of reconstru...   \n",
       "745  \\n        Focus on one step at the time. Write...   \n",
       "\n",
       "                                        conversational  \\\n",
       "0    parsing data from python iterator, how it coul...   \n",
       "1    Write python function to do operations with in...   \n",
       "2    Write shortest tutorial on creating RAG on ema...   \n",
       "3                                        what is FAISS   \n",
       "4     Transform given code to process large .mbox file   \n",
       "..                                                 ...   \n",
       "741  I want to tune optimal thresholds. Currently, ...   \n",
       "742  I want to use an LLM for listwise reranking in...   \n",
       "743  this is my code. I want to: Get nodes and edge...   \n",
       "744       I am working on the problem of reconstruc...   \n",
       "745  Focus on one step at the time. Write what is t...   \n",
       "\n",
       "                                                  code  \\\n",
       "0                                                        \n",
       "1                                                        \n",
       "2                                                        \n",
       "3                                                        \n",
       "4                                                        \n",
       "..                                                 ...   \n",
       "741  import pandas as pd\\nimport numpy as np\\nfrom ...   \n",
       "742  from transformers import AutoTokenizer, AutoMo...   \n",
       "743  def run_query(query, n_results):\\n    query_em...   \n",
       "744                                                      \n",
       "745                                                      \n",
       "\n",
       "                                                 other           gender  \\\n",
       "0                                                       Man (cisgender)   \n",
       "1    report_dt\\tsource\\tmetric_name\\tmetric_num\\tme...  Man (cisgender)   \n",
       "2                                                       Man (cisgender)   \n",
       "3                                                       Man (cisgender)   \n",
       "4     Transform given code to process large .mbox file  Man (cisgender)   \n",
       "..                                                 ...              ...   \n",
       "741  The narratives list looks like this:\\nnarrativ...  Man (cisgender)   \n",
       "742                                                     Man (cisgender)   \n",
       "743                                                     Man (cisgender)   \n",
       "744  Classic CV - Drone navigation\\nIf you ever tho...  Man (cisgender)   \n",
       "745                                                     Man (cisgender)   \n",
       "\n",
       "     user_id language  \n",
       "0          6       en  \n",
       "1          6       en  \n",
       "2          6       en  \n",
       "3          6       en  \n",
       "4          6       en  \n",
       "..       ...      ...  \n",
       "741       92       en  \n",
       "742       92       en  \n",
       "743       92       en  \n",
       "744        8       en  \n",
       "745        8       en  \n",
       "\n",
       "[746 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>message_id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>role</th>\n",
       "      <th>message_text</th>\n",
       "      <th>conversational</th>\n",
       "      <th>code</th>\n",
       "      <th>other</th>\n",
       "      <th>gender</th>\n",
       "      <th>user_id</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>parsing data from python iterator, how it coul...</td>\n",
       "      <td>parsing data from python iterator, how it coul...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>730</td>\n",
       "      <td>32</td>\n",
       "      <td>user</td>\n",
       "      <td>Write python function to do operations with in...</td>\n",
       "      <td>Write python function to do operations with in...</td>\n",
       "      <td></td>\n",
       "      <td>report_dt\\tsource\\tmetric_name\\tmetric_num\\tme...</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1133</td>\n",
       "      <td>55</td>\n",
       "      <td>user</td>\n",
       "      <td>Write shortest tutorial on creating RAG on ema...</td>\n",
       "      <td>Write shortest tutorial on creating RAG on ema...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1135</td>\n",
       "      <td>55</td>\n",
       "      <td>user</td>\n",
       "      <td>what is FAISS</td>\n",
       "      <td>what is FAISS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1137</td>\n",
       "      <td>55</td>\n",
       "      <td>user</td>\n",
       "      <td>Transform given code to process large .mbox file</td>\n",
       "      <td>Transform given code to process large .mbox file</td>\n",
       "      <td></td>\n",
       "      <td>Transform given code to process large .mbox file</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>748</td>\n",
       "      <td>1131</td>\n",
       "      <td>54</td>\n",
       "      <td>user</td>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nfrom ...</td>\n",
       "      <td>I want to tune optimal thresholds. Currently, ...</td>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nfrom ...</td>\n",
       "      <td>The narratives list looks like this:\\nnarrativ...</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>92</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>749</td>\n",
       "      <td>1532</td>\n",
       "      <td>71</td>\n",
       "      <td>user</td>\n",
       "      <td>from transformers import AutoTokenizer, AutoMo...</td>\n",
       "      <td>I want to use an LLM for listwise reranking in...</td>\n",
       "      <td>from transformers import AutoTokenizer, AutoMo...</td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>92</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>750</td>\n",
       "      <td>1646</td>\n",
       "      <td>82</td>\n",
       "      <td>user</td>\n",
       "      <td>def run_query(query, n_results):\\n    query_em...</td>\n",
       "      <td>this is my code. I want to: Get nodes and edge...</td>\n",
       "      <td>def run_query(query, n_results):\\n    query_em...</td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>92</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>751</td>\n",
       "      <td>1849</td>\n",
       "      <td>2</td>\n",
       "      <td>user</td>\n",
       "      <td>\\n    I am working on the problem of reconstru...</td>\n",
       "      <td>I am working on the problem of reconstruc...</td>\n",
       "      <td></td>\n",
       "      <td>Classic CV - Drone navigation\\nIf you ever tho...</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>8</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>752</td>\n",
       "      <td>1851</td>\n",
       "      <td>2</td>\n",
       "      <td>user</td>\n",
       "      <td>\\n        Focus on one step at the time. Write...</td>\n",
       "      <td>Focus on one step at the time. Write what is t...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>8</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>746 rows × 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data stats and subsampling of long conversations\n",
    "- subsampled 50 prompts from user 73, who had over 200"
   ],
   "id": "334981c03b3f6aaa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T10:58:18.202456Z",
     "start_time": "2025-09-13T10:58:18.195531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "users_per_gender = all_prompts.groupby('gender')['user_id'].nunique().reset_index(name='num_users')\n",
    "users_per_gender"
   ],
   "id": "cc639a91cdc93756",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              gender  num_users\n",
       "0    Man (cisgender)         15\n",
       "1  Woman (cisgender)         12"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>num_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T10:58:20.076684Z",
     "start_time": "2025-09-13T10:58:20.068198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages_per_user = all_prompts.groupby('user_id')['message_id'].nunique().reset_index(name='num_messages')\n",
    "messages_per_user"
   ],
   "id": "721f2c54de0aa65f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    user_id  num_messages\n",
       "0         6             9\n",
       "1         8             2\n",
       "2        11            11\n",
       "3        15             3\n",
       "4        16            25\n",
       "5        25             4\n",
       "6        28            22\n",
       "7        31             5\n",
       "8        34            66\n",
       "9        46             5\n",
       "10       47            51\n",
       "11       48            16\n",
       "12       55            36\n",
       "13       56             6\n",
       "14       60             7\n",
       "15       63             2\n",
       "16       65            10\n",
       "17       73           229\n",
       "18       77            20\n",
       "19       79            61\n",
       "20       81             5\n",
       "21       83            15\n",
       "22       88             5\n",
       "23       89            31\n",
       "24       90            14\n",
       "25       91            81\n",
       "26       92             5"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>num_messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>55</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>73</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>77</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>79</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>83</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>89</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>90</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>91</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T11:18:11.888053Z",
     "start_time": "2025-09-13T11:18:11.877959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assume your DataFrame is called `prompts`\n",
    "\n",
    "# 1. Separate out prompts for user 73 and other users\n",
    "user_73 = all_prompts[all_prompts['user_id'] == 73]\n",
    "other_users = all_prompts[all_prompts['user_id'] != 73]\n",
    "\n",
    "# 2. Randomly sample 50 prompts for user 73\n",
    "user_73_sampled = user_73.sample(n=50, random_state=42)\n",
    "\n",
    "# 3. Recombine\n",
    "prompts = pd.concat([other_users, user_73_sampled], ignore_index=True)\n",
    "\n",
    "subsampled_messages_per_user = prompts.groupby('user_id')['message_id'].nunique().reset_index(name='num_messages')\n",
    "subsampled_with_gender = subsampled_messages_per_user.merge(\n",
    "    prompts[['user_id', 'gender']].drop_duplicates(),\n",
    "    on='user_id',\n",
    "    how='left'\n",
    ")\n",
    "print(subsampled_with_gender.groupby(['gender']).sum())\n",
    "print(subsampled_with_gender.groupby(['user_id','gender']).mean())\n",
    "\n",
    "subsampled_with_gender\n",
    "\n"
   ],
   "id": "fe36a322109b08f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   user_id  num_messages\n",
      "gender                                  \n",
      "Man (cisgender)        780           282\n",
      "Woman (cisgender)      677           285\n",
      "                           num_messages\n",
      "user_id gender                         \n",
      "6       Man (cisgender)             9.0\n",
      "8       Man (cisgender)             2.0\n",
      "11      Woman (cisgender)          11.0\n",
      "15      Man (cisgender)             3.0\n",
      "16      Woman (cisgender)          25.0\n",
      "25      Man (cisgender)             4.0\n",
      "28      Woman (cisgender)          22.0\n",
      "31      Man (cisgender)             5.0\n",
      "34      Man (cisgender)            66.0\n",
      "46      Man (cisgender)             5.0\n",
      "47      Man (cisgender)            51.0\n",
      "48      Woman (cisgender)          16.0\n",
      "55      Woman (cisgender)          36.0\n",
      "56      Man (cisgender)             6.0\n",
      "60      Woman (cisgender)           7.0\n",
      "63      Woman (cisgender)           2.0\n",
      "65      Woman (cisgender)          10.0\n",
      "73      Woman (cisgender)          50.0\n",
      "77      Man (cisgender)            20.0\n",
      "79      Woman (cisgender)          61.0\n",
      "81      Man (cisgender)             5.0\n",
      "83      Man (cisgender)            15.0\n",
      "88      Man (cisgender)             5.0\n",
      "89      Woman (cisgender)          31.0\n",
      "90      Woman (cisgender)          14.0\n",
      "91      Man (cisgender)            81.0\n",
      "92      Man (cisgender)             5.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    user_id  num_messages             gender\n",
       "0         6             9    Man (cisgender)\n",
       "1         8             2    Man (cisgender)\n",
       "2        11            11  Woman (cisgender)\n",
       "3        15             3    Man (cisgender)\n",
       "4        16            25  Woman (cisgender)\n",
       "5        25             4    Man (cisgender)\n",
       "6        28            22  Woman (cisgender)\n",
       "7        31             5    Man (cisgender)\n",
       "8        34            66    Man (cisgender)\n",
       "9        46             5    Man (cisgender)\n",
       "10       47            51    Man (cisgender)\n",
       "11       48            16  Woman (cisgender)\n",
       "12       55            36  Woman (cisgender)\n",
       "13       56             6    Man (cisgender)\n",
       "14       60             7  Woman (cisgender)\n",
       "15       63             2  Woman (cisgender)\n",
       "16       65            10  Woman (cisgender)\n",
       "17       73            50  Woman (cisgender)\n",
       "18       77            20    Man (cisgender)\n",
       "19       79            61  Woman (cisgender)\n",
       "20       81             5    Man (cisgender)\n",
       "21       83            15    Man (cisgender)\n",
       "22       88             5    Man (cisgender)\n",
       "23       89            31  Woman (cisgender)\n",
       "24       90            14  Woman (cisgender)\n",
       "25       91            81    Man (cisgender)\n",
       "26       92             5    Man (cisgender)"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>num_messages</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34</td>\n",
       "      <td>66</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>55</td>\n",
       "      <td>36</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>73</td>\n",
       "      <td>50</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>77</td>\n",
       "      <td>20</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>79</td>\n",
       "      <td>61</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>83</td>\n",
       "      <td>15</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>89</td>\n",
       "      <td>31</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>90</td>\n",
       "      <td>14</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>91</td>\n",
       "      <td>81</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T11:18:18.051279Z",
     "start_time": "2025-09-13T11:18:18.045027Z"
    }
   },
   "cell_type": "code",
   "source": "prompts",
   "id": "16e79cf5dfe60aa1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     index  message_id  conversation_id  role  \\\n",
       "0        0           1                1  user   \n",
       "1        1         730               32  user   \n",
       "2        2        1133               55  user   \n",
       "3        3        1135               55  user   \n",
       "4        4        1137               55  user   \n",
       "..     ...         ...              ...   ...   \n",
       "562    391        1234               65  user   \n",
       "563    429        1322               65  user   \n",
       "564    334         484               21  user   \n",
       "565    444        1364               65  user   \n",
       "566    348         516               21  user   \n",
       "\n",
       "                                          message_text  \\\n",
       "0    parsing data from python iterator, how it coul...   \n",
       "1    Write python function to do operations with in...   \n",
       "2    Write shortest tutorial on creating RAG on ema...   \n",
       "3                                        what is FAISS   \n",
       "4     Transform given code to process large .mbox file   \n",
       "..                                                 ...   \n",
       "562             can we add peid for when pefile fails?   \n",
       "563  param_grid = {\\n    'min_samples': [5, 10, 20]...   \n",
       "564  i think i onlz want to think about the imbalan...   \n",
       "565  from sklearn.cluster import OPTICS\\nfrom sklea...   \n",
       "566  ah it did work.\\nnow i want to run:\\npredictor...   \n",
       "\n",
       "                                        conversational  \\\n",
       "0    parsing data from python iterator, how it coul...   \n",
       "1    Write python function to do operations with in...   \n",
       "2    Write shortest tutorial on creating RAG on ema...   \n",
       "3                                        what is FAISS   \n",
       "4     Transform given code to process large .mbox file   \n",
       "..                                                 ...   \n",
       "562             can we add peid for when pefile fails?   \n",
       "563                                 provide more steps   \n",
       "564  i think i only want to think about the imbalan...   \n",
       "565  this worked. but i do not have visualizations ...   \n",
       "566                 ah it did work. now i want to run:   \n",
       "\n",
       "                                                  code  \\\n",
       "0                                                        \n",
       "1                                                        \n",
       "2                                                        \n",
       "3                                                        \n",
       "4                                                        \n",
       "..                                                 ...   \n",
       "562                                                      \n",
       "563  param_grid = {\\n    'min_samples': [5, 10, 20]...   \n",
       "564                                                      \n",
       "565  from sklearn.cluster import OPTICS\\nfrom sklea...   \n",
       "566  predictor.fit(\\n    train_data=train_data,  # ...   \n",
       "\n",
       "                                                 other             gender  \\\n",
       "0                                                         Man (cisgender)   \n",
       "1    report_dt\\tsource\\tmetric_name\\tmetric_num\\tme...    Man (cisgender)   \n",
       "2                                                         Man (cisgender)   \n",
       "3                                                         Man (cisgender)   \n",
       "4     Transform given code to process large .mbox file    Man (cisgender)   \n",
       "..                                                 ...                ...   \n",
       "562                                                     Woman (cisgender)   \n",
       "563                                                     Woman (cisgender)   \n",
       "564                                                     Woman (cisgender)   \n",
       "565                                                     Woman (cisgender)   \n",
       "566  over each class 0 to 10 and create a model for...  Woman (cisgender)   \n",
       "\n",
       "     user_id language  label  \n",
       "0          6       en      0  \n",
       "1          6       en      0  \n",
       "2          6       en      0  \n",
       "3          6       en      0  \n",
       "4          6       en      0  \n",
       "..       ...      ...    ...  \n",
       "562       73       en      1  \n",
       "563       73       en      1  \n",
       "564       73       en      1  \n",
       "565       73       en      1  \n",
       "566       73       en      1  \n",
       "\n",
       "[567 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>message_id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>role</th>\n",
       "      <th>message_text</th>\n",
       "      <th>conversational</th>\n",
       "      <th>code</th>\n",
       "      <th>other</th>\n",
       "      <th>gender</th>\n",
       "      <th>user_id</th>\n",
       "      <th>language</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>parsing data from python iterator, how it coul...</td>\n",
       "      <td>parsing data from python iterator, how it coul...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>730</td>\n",
       "      <td>32</td>\n",
       "      <td>user</td>\n",
       "      <td>Write python function to do operations with in...</td>\n",
       "      <td>Write python function to do operations with in...</td>\n",
       "      <td></td>\n",
       "      <td>report_dt\\tsource\\tmetric_name\\tmetric_num\\tme...</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1133</td>\n",
       "      <td>55</td>\n",
       "      <td>user</td>\n",
       "      <td>Write shortest tutorial on creating RAG on ema...</td>\n",
       "      <td>Write shortest tutorial on creating RAG on ema...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1135</td>\n",
       "      <td>55</td>\n",
       "      <td>user</td>\n",
       "      <td>what is FAISS</td>\n",
       "      <td>what is FAISS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1137</td>\n",
       "      <td>55</td>\n",
       "      <td>user</td>\n",
       "      <td>Transform given code to process large .mbox file</td>\n",
       "      <td>Transform given code to process large .mbox file</td>\n",
       "      <td></td>\n",
       "      <td>Transform given code to process large .mbox file</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>391</td>\n",
       "      <td>1234</td>\n",
       "      <td>65</td>\n",
       "      <td>user</td>\n",
       "      <td>can we add peid for when pefile fails?</td>\n",
       "      <td>can we add peid for when pefile fails?</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>73</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>429</td>\n",
       "      <td>1322</td>\n",
       "      <td>65</td>\n",
       "      <td>user</td>\n",
       "      <td>param_grid = {\\n    'min_samples': [5, 10, 20]...</td>\n",
       "      <td>provide more steps</td>\n",
       "      <td>param_grid = {\\n    'min_samples': [5, 10, 20]...</td>\n",
       "      <td></td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>73</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>334</td>\n",
       "      <td>484</td>\n",
       "      <td>21</td>\n",
       "      <td>user</td>\n",
       "      <td>i think i onlz want to think about the imbalan...</td>\n",
       "      <td>i think i only want to think about the imbalan...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>73</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>444</td>\n",
       "      <td>1364</td>\n",
       "      <td>65</td>\n",
       "      <td>user</td>\n",
       "      <td>from sklearn.cluster import OPTICS\\nfrom sklea...</td>\n",
       "      <td>this worked. but i do not have visualizations ...</td>\n",
       "      <td>from sklearn.cluster import OPTICS\\nfrom sklea...</td>\n",
       "      <td></td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>73</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>348</td>\n",
       "      <td>516</td>\n",
       "      <td>21</td>\n",
       "      <td>user</td>\n",
       "      <td>ah it did work.\\nnow i want to run:\\npredictor...</td>\n",
       "      <td>ah it did work. now i want to run:</td>\n",
       "      <td>predictor.fit(\\n    train_data=train_data,  # ...</td>\n",
       "      <td>over each class 0 to 10 and create a model for...</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>73</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create label mapping",
   "id": "b77ffb63791e49e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T11:18:21.290857Z",
     "start_time": "2025-09-13T11:18:21.287113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "labels = prompts['gender'].astype('category')\n",
    "prompts['label'] = labels.cat.codes\n",
    "label2id = dict(enumerate(labels.cat.categories))\n",
    "label2id\n",
    "\n",
    "\n",
    "with open(\"finetune/label2id.json\", \"w\") as f:\n",
    "    json.dump(label2id, f)\n",
    "\n"
   ],
   "id": "c78f4018b93015de",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build dataset\n",
    "- group aware split: no prompts from the same user will occur in both sets\n",
    "- build dataset in huggingface format"
   ],
   "id": "d21fa90c937318b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T11:03:15.838078Z",
     "start_time": "2025-09-13T11:03:15.112538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from datasets import Dataset\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=42)\n",
    "groups = prompts['user_id']\n",
    "\n",
    "train_idx, val_idx = next(gss.split(prompts, groups=groups))\n",
    "train_prompts = prompts.iloc[train_idx]\n",
    "val_prompts = prompts.iloc[val_idx]\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_prompts[['conversational', 'label']])\n",
    "val_dataset = Dataset.from_pandas(val_prompts[['conversational', 'label']])\n",
    "\n",
    "train_dataset"
   ],
   "id": "ab35febd8ab087c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversational', 'label', '__index_level_0__'],\n",
       "    num_rows: 450\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model, Tokenizer & Data Collator",
   "id": "910248eadf91a898"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T11:18:27.046054Z",
     "start_time": "2025-09-13T11:18:26.592717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "num_labels = len(label2id)\n",
    "\n",
    "def model_init():\n",
    "    # Needed for Trainer's hyperparameter search to re-initialize your model each trial\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=num_labels\n",
    "    )\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"conversational\"],\n",
    "        truncation=True,\n",
    "        padding=False # padding is handled in the data collator\n",
    "    )\n"
   ],
   "id": "fbaf3d6a17d362e7",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check max sample size",
   "id": "c83ef298cd798e25"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T10:39:33.229387Z",
     "start_time": "2025-09-12T10:39:33.199624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Example: if your DataFrame is called user_prompts and the column is 'combined_prompts'\n",
    "# (Adjust to your actual variable/column names)\n",
    "texts = prompts['conversational'].tolist()\n",
    "\n",
    "# Count the tokens for each sample\n",
    "token_counts = [len(tokenizer.encode(text, add_special_tokens=True)) for text in texts]\n",
    "\n",
    "# Find the max, min, and average\n",
    "max_tokens = max(token_counts)\n",
    "min_tokens = min(token_counts)\n",
    "avg_tokens = sum(token_counts) / len(token_counts)\n",
    "\n",
    "print(f\"Max tokens: {max_tokens}\")\n",
    "print(f\"Min tokens: {min_tokens}\")\n"
   ],
   "id": "9824abc597d51e24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tokens: 407\n",
      "Min tokens: 4\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenize",
   "id": "db35919984043505"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T11:03:21.108135Z",
     "start_time": "2025-09-13T11:03:21.017673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset"
   ],
   "id": "99641e35b9519b91",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 450/450 [00:00<00:00, 23254.61 examples/s]\n",
      "Map: 100%|██████████| 117/117 [00:00<00:00, 13958.74 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversational', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 117\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Trainer\n",
   "id": "72547bbbb809ac45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T11:16:04.734556Z",
     "start_time": "2025-09-13T11:16:04.444435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    precision = precision_score(labels, preds, average='weighted')\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8, # finetune this\n",
    "    per_device_eval_batch_size=8, # finetune this\n",
    "    num_train_epochs=10, # finetune this\n",
    "    learning_rate=3.2e-5, # finetune this\n",
    "    #weight_decay= #\n",
    "    #warmup_steps = 10,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    logging_steps=50,         \n",
    "    logging_strategy=\"steps\",\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n"
   ],
   "id": "5f5b00d0e2382b5",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 41\u001B[39m\n\u001B[32m     12\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[32m     13\u001B[39m         \u001B[33m'\u001B[39m\u001B[33maccuracy\u001B[39m\u001B[33m'\u001B[39m: acc,\n\u001B[32m     14\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mf1\u001B[39m\u001B[33m'\u001B[39m: f1,\n\u001B[32m     15\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mprecision\u001B[39m\u001B[33m'\u001B[39m: precision,\n\u001B[32m     16\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mrecall\u001B[39m\u001B[33m'\u001B[39m: recall\n\u001B[32m     17\u001B[39m     }\n\u001B[32m     20\u001B[39m training_args = TrainingArguments(\n\u001B[32m     21\u001B[39m     output_dir=\u001B[33m\"\u001B[39m\u001B[33m./results\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     22\u001B[39m     eval_strategy=\u001B[33m\"\u001B[39m\u001B[33mepoch\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     34\u001B[39m     logging_strategy=\u001B[33m\"\u001B[39m\u001B[33msteps\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     35\u001B[39m )\n\u001B[32m     38\u001B[39m trainer = Trainer(\n\u001B[32m     39\u001B[39m     model_init=model_init,\n\u001B[32m     40\u001B[39m     args=training_args,\n\u001B[32m---> \u001B[39m\u001B[32m41\u001B[39m     train_dataset=\u001B[43mtrain_dataset\u001B[49m,\n\u001B[32m     42\u001B[39m     eval_dataset=val_dataset,\n\u001B[32m     43\u001B[39m     tokenizer=tokenizer,\n\u001B[32m     44\u001B[39m     data_collator=data_collator,\n\u001B[32m     45\u001B[39m     callbacks=[EarlyStoppingCallback(early_stopping_patience=\u001B[32m3\u001B[39m)],\n\u001B[32m     46\u001B[39m     compute_metrics=compute_metrics,\n\u001B[32m     47\u001B[39m )\n",
      "\u001B[31mNameError\u001B[39m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter Search\n",
    "- optimizing for accuracy since classes are balanced (12:15)\n",
    "\n",
    "first search run:\n",
    "- learning_rate between  5e-6, 5e-5, log=True\n",
    "- num_train_epochs between 2, 5\n",
    "- per_device_train_batch_size between 4, 8\n",
    "- per_device_eval_batch_size 4, 8\n",
    "- Best hyperparameters: {'learning_rate': 1.752433329903465e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 8}\n",
    "- Best eval accuracy: 0.6153846153846154\n",
    "\n",
    "second search run:\n",
    "- batch sizes 8\n",
    "- epochs 5\n",
    "- learing rate between 5e-6, 2e-5\n",
    "- Best hyperparameters: {'learning_rate': 1.2308237496976495e-05}\n",
    "- Best eval accuracy: 0.6837606837606838\n",
    "\n",
    "third run:\n",
    "batch sizes 4\n",
    "- learing rate between 5e-6, 2e-5\n",
    "- Best hyperparameters: {'learning_rate': 1.2665150015950181e-05}\n",
    "- Best eval accuracy: 0.6239316239316239\n",
    "\n",
    "fourth run:\n",
    "- batch sizes 8\n",
    "- learning_rate between 1e-5, 3e-5\n",
    "- highest accuracy 0.726496\n",
    "- learning_rate': 2.8213598460702224e-05\n",
    "\n",
    "fifth run:\n",
    "- batch sizes 8\n",
    "- learning_rate between 3e-5, 4e-5\n",
    "- highest accuracy 0.760684\n",
    "- learning_rate':  3.035495167103403e-05\n",
    "\n",
    "sixth run:\n",
    "- batch sizes 8\n",
    "- learning_rate between 2.5e-5, 3.5e-5\n",
    "- highest accuracy 0.803419\tat 3.20605942472665e-05 at epoch 3\n",
    "- also good: 0.77777 at 3.2759208826863756e-05 at epoch 3\n",
    "- 0.726496 at  2.9592151393562346e-05 at epoch 3\n",
    "- 0.752137\t3.443498945690748e-05 at epoch 3\n",
    "\n",
    "7th run:\n",
    "- batch sizes 8\n",
    "- learning_rate between 3.1e-5, 3.4e-5\n",
    "- highest accuracy 0.752137\tat 3.246309190194653e-05 at epoch 3\n",
    "- and at 3.186004390546374e-05 at epoch 2\n",
    "\n",
    "8th run:\n",
    "- batch sizes 8\n",
    "- learning_rate between 1e-5, 1.5e-5\n",
    "- highest accuracy 0.69\tat 1.25e-5 at epoch 5\n"
   ],
   "id": "d2f8ea28f9789749"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T10:49:11.297959Z",
     "start_time": "2025-09-13T10:49:08.275205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1.5e-5, log=True),\n",
    "    }\n",
    "\n",
    "\n",
    "best_run = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    hp_space=hp_space,\n",
    "    n_trials=10,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_accuracy\"]\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters:\", best_run.hyperparameters)\n",
    "print(\"Best eval accuracy:\", best_run.objective)\n"
   ],
   "id": "91bbc0ecaf26e2c4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 12:49:08,318] A new study created in memory with name: no-name-1402de38-dbe6-4101-b5dc-b70b1fe2da08\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 20/570 00:02 < 01:01, 8.90 it/s, Epoch 0.33/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "b4b8468db3cdd8027f577dbeec2b1dca"
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-09-13 12:49:11,049] Trial 0 failed with parameters: {'learning_rate': 1.1629381989895705e-05} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/integrations/integration_utils.py\", line 277, in _objective\n",
      "    trainer.train(resume_from_checkpoint=checkpoint, trial=trial)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/trainer.py\", line 2328, in train\n",
      "    return inner_training_loop(\n",
      "        args=args,\n",
      "    ...<2 lines>...\n",
      "        ignore_keys_for_eval=ignore_keys_for_eval,\n",
      "    )\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/trainer.py\", line 2677, in _inner_training_loop\n",
      "    and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))\n",
      "                                      ~~~~~~~~~~~^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-09-13 12:49:11,050] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mhp_space\u001B[39m(trial):\n\u001B[32m      2\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[32m      3\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mlearning_rate\u001B[39m\u001B[33m\"\u001B[39m: trial.suggest_float(\u001B[33m\"\u001B[39m\u001B[33mlearning_rate\u001B[39m\u001B[33m\"\u001B[39m, \u001B[32m1e-5\u001B[39m, \u001B[32m1.5e-5\u001B[39m, log=\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[32m      4\u001B[39m     }\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m best_run = \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhyperparameter_search\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdirection\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmaximize\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhp_space\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhp_space\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompute_objective\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43meval_accuracy\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mBest hyperparameters:\u001B[39m\u001B[33m\"\u001B[39m, best_run.hyperparameters)\n\u001B[32m     15\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mBest eval accuracy:\u001B[39m\u001B[33m\"\u001B[39m, best_run.objective)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/trainer.py:3764\u001B[39m, in \u001B[36mTrainer.hyperparameter_search\u001B[39m\u001B[34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001B[39m\n\u001B[32m   3761\u001B[39m \u001B[38;5;28mself\u001B[39m.hp_name = hp_name\n\u001B[32m   3762\u001B[39m \u001B[38;5;28mself\u001B[39m.compute_objective = default_compute_objective \u001B[38;5;28;01mif\u001B[39;00m compute_objective \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m compute_objective\n\u001B[32m-> \u001B[39m\u001B[32m3764\u001B[39m best_run = \u001B[43mbackend_obj\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdirection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3766\u001B[39m \u001B[38;5;28mself\u001B[39m.hp_search_backend = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   3767\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m best_run\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/hyperparameter_search.py:72\u001B[39m, in \u001B[36mOptunaBackend.run\u001B[39m\u001B[34m(self, trainer, n_trials, direction, **kwargs)\u001B[39m\n\u001B[32m     71\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m, trainer, n_trials: \u001B[38;5;28mint\u001B[39m, direction: \u001B[38;5;28mstr\u001B[39m, **kwargs):\n\u001B[32m---> \u001B[39m\u001B[32m72\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrun_hp_search_optuna\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdirection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/integrations/integration_utils.py:295\u001B[39m, in \u001B[36mrun_hp_search_optuna\u001B[39m\u001B[34m(trainer, n_trials, direction, **kwargs)\u001B[39m\n\u001B[32m    293\u001B[39m direction = \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m directions \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m direction\n\u001B[32m    294\u001B[39m study = optuna.create_study(direction=direction, directions=directions, **kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m295\u001B[39m \u001B[43mstudy\u001B[49m\u001B[43m.\u001B[49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_objective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    296\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m study._is_multi_objective():\n\u001B[32m    297\u001B[39m     best_trial = study.best_trial\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/optuna/study/study.py:490\u001B[39m, in \u001B[36mStudy.optimize\u001B[39m\u001B[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[39m\n\u001B[32m    388\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34moptimize\u001B[39m(\n\u001B[32m    389\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    390\u001B[39m     func: ObjectiveFuncType,\n\u001B[32m   (...)\u001B[39m\u001B[32m    397\u001B[39m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    398\u001B[39m ) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    399\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[32m    400\u001B[39m \n\u001B[32m    401\u001B[39m \u001B[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    488\u001B[39m \u001B[33;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[32m    489\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m490\u001B[39m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    491\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    492\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    493\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    494\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    495\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    496\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    497\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    498\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    499\u001B[39m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    500\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/optuna/study/_optimize.py:63\u001B[39m, in \u001B[36m_optimize\u001B[39m\u001B[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[39m\n\u001B[32m     61\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     62\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs == \u001B[32m1\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     64\u001B[39m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     65\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     66\u001B[39m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     67\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     68\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     69\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     70\u001B[39m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     71\u001B[39m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     72\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     73\u001B[39m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     75\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     76\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs == -\u001B[32m1\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/optuna/study/_optimize.py:160\u001B[39m, in \u001B[36m_optimize_sequential\u001B[39m\u001B[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[39m\n\u001B[32m    157\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m    159\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m160\u001B[39m     frozen_trial_id = \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    161\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    162\u001B[39m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[32m    163\u001B[39m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[32m    164\u001B[39m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[32m    165\u001B[39m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[32m    166\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/optuna/study/_optimize.py:258\u001B[39m, in \u001B[36m_run_trial\u001B[39m\u001B[34m(study, func, catch)\u001B[39m\n\u001B[32m    251\u001B[39m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mShould not reach.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    253\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    254\u001B[39m     updated_state == TrialState.FAIL\n\u001B[32m    255\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    256\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[32m    257\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m258\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[32m    259\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m trial._trial_id\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/optuna/study/_optimize.py:201\u001B[39m, in \u001B[36m_run_trial\u001B[39m\u001B[34m(study, func, catch)\u001B[39m\n\u001B[32m    199\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001B[32m    200\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m201\u001B[39m         value_or_values = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    202\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions.TrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    203\u001B[39m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[32m    204\u001B[39m         state = TrialState.PRUNED\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/integrations/integration_utils.py:277\u001B[39m, in \u001B[36mrun_hp_search_optuna.<locals>._objective\u001B[39m\u001B[34m(trial, checkpoint_dir)\u001B[39m\n\u001B[32m    275\u001B[39m     trainer.train(resume_from_checkpoint=checkpoint, trial=trial)\n\u001B[32m    276\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m277\u001B[39m     \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    278\u001B[39m \u001B[38;5;66;03m# If there hasn't been any evaluation during the training loop.\u001B[39;00m\n\u001B[32m    279\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(trainer, \u001B[33m\"\u001B[39m\u001B[33mobjective\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/trainer.py:2328\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   2326\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   2327\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2328\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2329\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2330\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2331\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2332\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2333\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/trainer.py:2677\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   2671\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m context():\n\u001B[32m   2672\u001B[39m     tr_loss_step = \u001B[38;5;28mself\u001B[39m.training_step(model, inputs, num_items_in_batch)\n\u001B[32m   2674\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   2675\u001B[39m     args.logging_nan_inf_filter\n\u001B[32m   2676\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[32m-> \u001B[39m\u001B[32m2677\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m (torch.isnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43misinf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr_loss_step\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m   2678\u001B[39m ):\n\u001B[32m   2679\u001B[39m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[32m   2680\u001B[39m     tr_loss = tr_loss + tr_loss / (\u001B[32m1\u001B[39m + \u001B[38;5;28mself\u001B[39m.state.global_step - \u001B[38;5;28mself\u001B[39m._globalstep_last_logged)\n\u001B[32m   2681\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Cross Validation\n",
    "\n",
    "- selected hyperparameters: lr 3.2e-5, batchsizes 8, epochs 10"
   ],
   "id": "b18154b7d4cc2f1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T11:31:08.194862Z",
     "start_time": "2025-09-13T11:27:15.033502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "groups = prompts['user_id'].values\n",
    "texts = prompts['conversational'].tolist()\n",
    "labels = prompts['label'].tolist()\n",
    "n_splits = 5  # e.g. 5-fold CV\n",
    "\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(texts, labels, groups)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "\n",
    "    train_prompts = prompts.iloc[train_idx]\n",
    "    val_prompts = prompts.iloc[val_idx]\n",
    "\n",
    "    train_dataset = Dataset.from_pandas(train_prompts[['conversational', 'label']])\n",
    "    val_dataset = Dataset.from_pandas(val_prompts[['conversational', 'label']])\n",
    "\n",
    "    train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "    val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    # Set up Trainer with model/tokenizer/data_collator as before\n",
    "    trainer = Trainer(\n",
    "        model_init=model_init,\n",
    "        args=TrainingArguments(\n",
    "            output_dir=f\"./fold_{fold+1}_results\",\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            logging_dir=f\"./fold_{fold+1}_logs\",\n",
    "            per_device_train_batch_size=8,\n",
    "            per_device_eval_batch_size=8,\n",
    "            num_train_epochs=5,\n",
    "            learning_rate=3.2e-5,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            logging_steps=50,\n",
    "            logging_strategy=\"steps\",\n",
    "        ),\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_metrics = trainer.evaluate()\n",
    "    print(f\"Fold {fold + 1} metrics:\", eval_metrics)\n",
    "    all_results.append(eval_metrics)\n",
    "\n",
    "print(all_results)\n",
    "\n",
    "\n"
   ],
   "id": "591e7b302dd48833",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 453/453 [00:00<00:00, 48023.95 examples/s]\n",
      "Map: 100%|██████████| 114/114 [00:00<00:00, 25411.92 examples/s]\n",
      "/var/folders/_h/dm14sczn7s77lrr765t54y7h0000gn/T/ipykernel_37089/90554748.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [285/285 00:44, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.633500</td>\n",
       "      <td>1.411721</td>\n",
       "      <td>0.324561</td>\n",
       "      <td>0.468703</td>\n",
       "      <td>0.982900</td>\n",
       "      <td>0.324561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.434400</td>\n",
       "      <td>1.716535</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.488820</td>\n",
       "      <td>0.982912</td>\n",
       "      <td>0.342105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.307600</td>\n",
       "      <td>2.358241</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.643860</td>\n",
       "      <td>0.965215</td>\n",
       "      <td>0.491228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.126300</td>\n",
       "      <td>2.147707</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.718226</td>\n",
       "      <td>0.967936</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.152700</td>\n",
       "      <td>3.073742</td>\n",
       "      <td>0.464912</td>\n",
       "      <td>0.619802</td>\n",
       "      <td>0.964207</td>\n",
       "      <td>0.464912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "127b85601ff23121527599a6076ecaff"
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "b7d12e920ff3f7c873630722bb998e73"
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 metrics: {'eval_loss': 2.1477065086364746, 'eval_accuracy': 0.5789473684210527, 'eval_f1': 0.7182259018332348, 'eval_precision': 0.9679359383306753, 'eval_recall': 0.5789473684210527, 'eval_runtime': 0.4268, 'eval_samples_per_second': 267.093, 'eval_steps_per_second': 35.144, 'epoch': 5.0}\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 454/454 [00:00<00:00, 52160.24 examples/s]\n",
      "Map: 100%|██████████| 113/113 [00:00<00:00, 26848.49 examples/s]\n",
      "/var/folders/_h/dm14sczn7s77lrr765t54y7h0000gn/T/ipykernel_37089/90554748.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [285/285 00:43, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.686200</td>\n",
       "      <td>0.663933</td>\n",
       "      <td>0.628319</td>\n",
       "      <td>0.606065</td>\n",
       "      <td>0.592322</td>\n",
       "      <td>0.628319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.622300</td>\n",
       "      <td>0.687484</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>0.631491</td>\n",
       "      <td>0.620416</td>\n",
       "      <td>0.672566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.468100</td>\n",
       "      <td>0.817659</td>\n",
       "      <td>0.681416</td>\n",
       "      <td>0.695783</td>\n",
       "      <td>0.770444</td>\n",
       "      <td>0.681416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.277700</td>\n",
       "      <td>1.386240</td>\n",
       "      <td>0.610619</td>\n",
       "      <td>0.619191</td>\n",
       "      <td>0.796581</td>\n",
       "      <td>0.610619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.192800</td>\n",
       "      <td>1.331715</td>\n",
       "      <td>0.681416</td>\n",
       "      <td>0.695526</td>\n",
       "      <td>0.781005</td>\n",
       "      <td>0.681416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "ec9ae30259dea30125e982b4118a8d24"
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "632fd73af8a2bcc983593cc828fb2bc2"
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 metrics: {'eval_loss': 0.8176594972610474, 'eval_accuracy': 0.6814159292035398, 'eval_f1': 0.6957834461218115, 'eval_precision': 0.7704438086366359, 'eval_recall': 0.6814159292035398, 'eval_runtime': 0.5037, 'eval_samples_per_second': 224.335, 'eval_steps_per_second': 29.779, 'epoch': 5.0}\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 453/453 [00:00<00:00, 48171.28 examples/s]\n",
      "Map: 100%|██████████| 114/114 [00:00<00:00, 12916.01 examples/s]\n",
      "/var/folders/_h/dm14sczn7s77lrr765t54y7h0000gn/T/ipykernel_37089/90554748.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [285/285 00:44, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.672700</td>\n",
       "      <td>0.969295</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.472962</td>\n",
       "      <td>0.697931</td>\n",
       "      <td>0.456140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.461000</td>\n",
       "      <td>1.133371</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.607909</td>\n",
       "      <td>0.713605</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.258000</td>\n",
       "      <td>2.107345</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.554896</td>\n",
       "      <td>0.703083</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.245300</td>\n",
       "      <td>2.746616</td>\n",
       "      <td>0.517544</td>\n",
       "      <td>0.545838</td>\n",
       "      <td>0.699297</td>\n",
       "      <td>0.517544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>2.866377</td>\n",
       "      <td>0.535088</td>\n",
       "      <td>0.563860</td>\n",
       "      <td>0.706794</td>\n",
       "      <td>0.535088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "c95911bb9f8fab0cf22f5d405d39f8a5"
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "64f928a7f55969c1a395c42cbe7870c3"
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 metrics: {'eval_loss': 1.1333709955215454, 'eval_accuracy': 0.5789473684210527, 'eval_f1': 0.6079093902460049, 'eval_precision': 0.7136051335234638, 'eval_recall': 0.5789473684210527, 'eval_runtime': 0.365, 'eval_samples_per_second': 312.31, 'eval_steps_per_second': 41.093, 'epoch': 5.0}\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 453/453 [00:00<00:00, 53601.71 examples/s]\n",
      "Map: 100%|██████████| 114/114 [00:00<00:00, 31155.97 examples/s]\n",
      "/var/folders/_h/dm14sczn7s77lrr765t54y7h0000gn/T/ipykernel_37089/90554748.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [285/285 00:47, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.681400</td>\n",
       "      <td>0.590056</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.719298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.506200</td>\n",
       "      <td>0.579366</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.746586</td>\n",
       "      <td>0.790102</td>\n",
       "      <td>0.754386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.326600</td>\n",
       "      <td>0.938303</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.756391</td>\n",
       "      <td>0.796053</td>\n",
       "      <td>0.763158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.383900</td>\n",
       "      <td>1.154529</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.775714</td>\n",
       "      <td>0.808108</td>\n",
       "      <td>0.780702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.217500</td>\n",
       "      <td>1.020075</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.778641</td>\n",
       "      <td>0.791560</td>\n",
       "      <td>0.780702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "d0f888402707935316fb1fb6ac4785b4"
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "8165d1171cf063c5a7f23fb83d4a47cd"
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 metrics: {'eval_loss': 1.154529333114624, 'eval_accuracy': 0.7807017543859649, 'eval_f1': 0.7757141732903124, 'eval_precision': 0.8081081081081082, 'eval_recall': 0.7807017543859649, 'eval_runtime': 0.3332, 'eval_samples_per_second': 342.121, 'eval_steps_per_second': 45.016, 'epoch': 5.0}\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 455/455 [00:00<00:00, 53240.57 examples/s]\n",
      "Map: 100%|██████████| 112/112 [00:00<00:00, 32372.82 examples/s]\n",
      "/var/folders/_h/dm14sczn7s77lrr765t54y7h0000gn/T/ipykernel_37089/90554748.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [285/285 00:44, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>1.385454</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.276603</td>\n",
       "      <td>0.906995</td>\n",
       "      <td>0.196429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.502400</td>\n",
       "      <td>1.408104</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.599888</td>\n",
       "      <td>0.902794</td>\n",
       "      <td>0.464286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.333100</td>\n",
       "      <td>1.685343</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.684969</td>\n",
       "      <td>0.912435</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.388400</td>\n",
       "      <td>3.454474</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.492938</td>\n",
       "      <td>0.886711</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>3.348182</td>\n",
       "      <td>0.401786</td>\n",
       "      <td>0.539513</td>\n",
       "      <td>0.894404</td>\n",
       "      <td>0.401786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "10537e5fd1b4492c934c95a0f79f3922"
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "9ac1ba126ff8bce8385e7ea8ae42ce9d"
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 metrics: {'eval_loss': 1.685342788696289, 'eval_accuracy': 0.5625, 'eval_f1': 0.6849691051528192, 'eval_precision': 0.9124348958333333, 'eval_recall': 0.5624999999999999, 'eval_runtime': 0.4555, 'eval_samples_per_second': 245.91, 'eval_steps_per_second': 30.739, 'epoch': 5.0}\n",
      "[{'eval_loss': 2.1477065086364746, 'eval_accuracy': 0.5789473684210527, 'eval_f1': 0.7182259018332348, 'eval_precision': 0.9679359383306753, 'eval_recall': 0.5789473684210527, 'eval_runtime': 0.4268, 'eval_samples_per_second': 267.093, 'eval_steps_per_second': 35.144, 'epoch': 5.0}, {'eval_loss': 0.8176594972610474, 'eval_accuracy': 0.6814159292035398, 'eval_f1': 0.6957834461218115, 'eval_precision': 0.7704438086366359, 'eval_recall': 0.6814159292035398, 'eval_runtime': 0.5037, 'eval_samples_per_second': 224.335, 'eval_steps_per_second': 29.779, 'epoch': 5.0}, {'eval_loss': 1.1333709955215454, 'eval_accuracy': 0.5789473684210527, 'eval_f1': 0.6079093902460049, 'eval_precision': 0.7136051335234638, 'eval_recall': 0.5789473684210527, 'eval_runtime': 0.365, 'eval_samples_per_second': 312.31, 'eval_steps_per_second': 41.093, 'epoch': 5.0}, {'eval_loss': 1.154529333114624, 'eval_accuracy': 0.7807017543859649, 'eval_f1': 0.7757141732903124, 'eval_precision': 0.8081081081081082, 'eval_recall': 0.7807017543859649, 'eval_runtime': 0.3332, 'eval_samples_per_second': 342.121, 'eval_steps_per_second': 45.016, 'epoch': 5.0}, {'eval_loss': 1.685342788696289, 'eval_accuracy': 0.5625, 'eval_f1': 0.6849691051528192, 'eval_precision': 0.9124348958333333, 'eval_recall': 0.5624999999999999, 'eval_runtime': 0.4555, 'eval_samples_per_second': 245.91, 'eval_steps_per_second': 30.739, 'epoch': 5.0}]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T11:41:28.798802Z",
     "start_time": "2025-09-13T11:41:28.786529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = pd.DataFrame(all_results)\n",
    "results.describe()\n"
   ],
   "id": "aba3e24c8fdb3278",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       eval_loss  eval_accuracy   eval_f1  eval_precision  eval_recall  \\\n",
       "count   5.000000       5.000000  5.000000        5.000000     5.000000   \n",
       "mean    1.387722       0.636502  0.696520        0.834506     0.636502   \n",
       "std     0.526830       0.093424  0.060681        0.104036     0.093424   \n",
       "min     0.817659       0.562500  0.607909        0.713605     0.562500   \n",
       "25%     1.133371       0.578947  0.684969        0.770444     0.578947   \n",
       "50%     1.154529       0.578947  0.695783        0.808108     0.578947   \n",
       "75%     1.685343       0.681416  0.718226        0.912435     0.681416   \n",
       "max     2.147707       0.780702  0.775714        0.967936     0.780702   \n",
       "\n",
       "       eval_runtime  eval_samples_per_second  eval_steps_per_second  epoch  \n",
       "count      5.000000                 5.000000               5.000000    5.0  \n",
       "mean       0.416840               278.353800              36.354200    5.0  \n",
       "std        0.068596                48.261568               6.589979    0.0  \n",
       "min        0.333200               224.335000              29.779000    5.0  \n",
       "25%        0.365000               245.910000              30.739000    5.0  \n",
       "50%        0.426800               267.093000              35.144000    5.0  \n",
       "75%        0.455500               312.310000              41.093000    5.0  \n",
       "max        0.503700               342.121000              45.016000    5.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.387722</td>\n",
       "      <td>0.636502</td>\n",
       "      <td>0.696520</td>\n",
       "      <td>0.834506</td>\n",
       "      <td>0.636502</td>\n",
       "      <td>0.416840</td>\n",
       "      <td>278.353800</td>\n",
       "      <td>36.354200</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.526830</td>\n",
       "      <td>0.093424</td>\n",
       "      <td>0.060681</td>\n",
       "      <td>0.104036</td>\n",
       "      <td>0.093424</td>\n",
       "      <td>0.068596</td>\n",
       "      <td>48.261568</td>\n",
       "      <td>6.589979</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.817659</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.607909</td>\n",
       "      <td>0.713605</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.333200</td>\n",
       "      <td>224.335000</td>\n",
       "      <td>29.779000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.133371</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.684969</td>\n",
       "      <td>0.770444</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>245.910000</td>\n",
       "      <td>30.739000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.154529</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.695783</td>\n",
       "      <td>0.808108</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>267.093000</td>\n",
       "      <td>35.144000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.685343</td>\n",
       "      <td>0.681416</td>\n",
       "      <td>0.718226</td>\n",
       "      <td>0.912435</td>\n",
       "      <td>0.681416</td>\n",
       "      <td>0.455500</td>\n",
       "      <td>312.310000</td>\n",
       "      <td>41.093000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.147707</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.775714</td>\n",
       "      <td>0.967936</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.503700</td>\n",
       "      <td>342.121000</td>\n",
       "      <td>45.016000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a9f033108d5bd678"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
