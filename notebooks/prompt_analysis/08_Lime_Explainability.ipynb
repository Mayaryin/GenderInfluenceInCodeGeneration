{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Explain predictions using Lime",
   "id": "55befd714062ceb8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:57:14.796353Z",
     "start_time": "2025-09-22T19:57:14.774725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import json\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import torch\n",
    "from scipy.special import softmax\n",
    "from IPython.display import display, HTML\n",
    "import sqlite3\n",
    "\n",
    "conn  = sqlite3.connect('../../giicg.db')\n",
    "data_set= pd.read_sql(\"Select * from validation_set\", conn)\n",
    "conn.close()\n"
   ],
   "id": "340a578a58985263",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Model and Tokenizer",
   "id": "a8aa5f062da9d973"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T20:24:09.500655Z",
     "start_time": "2025-09-22T20:24:07.961945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "fine_tuned_model_path = \"Mayaryin/gender-prompt-roberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(fine_tuned_model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(fine_tuned_model_path).to(device)\n",
    "\n",
    "with open(\"finetune/label2id.json\", \"r\") as f:\n",
    "    label2id = json.load(f)"
   ],
   "id": "3eccbba0b882c7a4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Explain",
   "id": "606a9e247ddbec1"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-22T20:24:10.895794Z",
     "start_time": "2025-09-22T20:24:10.876704Z"
    }
   },
   "source": [
    "class_names = list(label2id.keys())\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "\n",
    "def predict(texts):\n",
    "    # Tokenize and move each tensor to the correct device\n",
    "    encodings = tokenizer(\n",
    "        texts, return_tensors=\"pt\", truncation=True, padding=True\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encodings)\n",
    "        logits = outputs.logits.cpu().numpy() # for batch processing as expected by limes explainer, since it perturbs the text internally\n",
    "        probs = softmax(logits, axis=1)\n",
    "    return probs\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Set up custom explainer with roberta tokenizer",
   "id": "bf69047e245e234b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T20:24:12.840528Z",
     "start_time": "2025-09-22T20:24:12.831690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SubwordLimeTextExplainer(LimeTextExplainer):\n",
    "    def __init__(self, hf_tokenizer, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hf_tokenizer = hf_tokenizer\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        # Tokenize the text into subwords (by default returns list of strings/tokens)\n",
    "        # Note: This usually includes special tokens, so we skip those\n",
    "        tokens = self.hf_tokenizer.tokenize(text)\n",
    "        return tokens\n",
    "\n",
    "    def untokenize(self, tokens):\n",
    "        # Convert the list of subword tokens back to a text string\n",
    "        return self.hf_tokenizer.convert_tokens_to_string(tokens)"
   ],
   "id": "9c71aeab0d2f8020",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-22T20:24:14.446455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "explainer = SubwordLimeTextExplainer(hf_tokenizer=tokenizer, class_names=class_names)\n",
    "\n",
    "# Sample column name is 'text'\n",
    "importance_agg = defaultdict(float)  # token -> sum of scores\n",
    "token_counts = defaultdict(int)      # token -> number of appearances in explanations\n",
    "\n",
    "for sample_text in tqdm(data_set['conversational'], desc=\"Explaining samples\"):\n",
    "    explanation = explainer.explain_instance(\n",
    "        sample_text,\n",
    "        predict,\n",
    "        num_features=100,  # adjust as needed\n",
    "        labels=[1]         # or the class index you're interested in\n",
    "    )\n",
    "\n",
    "    # Get the explanation as a list of (token, weight) tuples\n",
    "    token_weights = explanation.as_list(label=1)  # use correct label\n",
    "\n",
    "    for token, weight in token_weights:\n",
    "        importance_agg[token] += weight\n",
    "        token_counts[token] += 1\n",
    "\n",
    "# Now aggregate: for example, calculate average importance for each token\n",
    "average_importance = {token: importance_agg[token] / token_counts[token]\n",
    "                      for token in importance_agg}\n",
    "\n",
    "# Optionally, sort tokens by their average importance (desc)\n",
    "sorted_tokens = sorted(average_importance.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Print top 20 tokens\n",
    "print(\"Top tokens by average importance:\")\n",
    "for token, score in sorted_tokens[:20]:\n",
    "    print(f\"{token}: {score:.4f}\")\n"
   ],
   "id": "cf43858afe19b706",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explaining samples:   3%|â–Ž         | 3/114 [00:50<33:37, 18.17s/it]"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
