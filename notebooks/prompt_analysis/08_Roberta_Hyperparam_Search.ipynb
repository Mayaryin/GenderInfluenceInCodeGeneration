{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter Search\n",
    "\n",
    "- optimizing for accuracy since classes are balanced (12:15)\n",
    "\n",
    "first search run:\n",
    "- learning_rate between  5e-6, 5e-5, log=True\n",
    "- num_train_epochs between 2, 5\n",
    "- per_device_train_batch_size between 4, 8\n",
    "- per_device_eval_batch_size 4, 8\n",
    "- Best hyperparameters: {'learning_rate': 1.752433329903465e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 8}\n",
    "- Best eval accuracy: 0.6153846153846154\n",
    "\n",
    "second search run:\n",
    "- batch sizes 8\n",
    "- epochs 5\n",
    "- learing rate between 5e-6, 2e-5\n",
    "- Best hyperparameters: {'learning_rate': 1.2308237496976495e-05}\n",
    "- Best eval accuracy: 0.6837606837606838\n",
    "\n",
    "third run:\n",
    "batch sizes 4\n",
    "- learing rate between 5e-6, 2e-5\n",
    "- Best hyperparameters: {'learning_rate': 1.2665150015950181e-05}\n",
    "- Best eval accuracy: 0.6239316239316239\n",
    "\n",
    "fourth run:\n",
    "- batch sizes 8\n",
    "- learning_rate between 1e-5, 3e-5\n",
    "- highest accuracy 0.726496\n",
    "- learning_rate': 2.8213598460702224e-05\n",
    "\n",
    "fifth run:\n",
    "- batch sizes 8\n",
    "- learning_rate between 3e-5, 4e-5\n",
    "- highest accuracy 0.760684\n",
    "- learning_rate':  3.035495167103403e-05\n",
    "\n",
    "sixth run:\n",
    "- batch sizes 8\n",
    "- learning_rate between 2.5e-5, 3.5e-5\n",
    "- highest accuracy 0.803419\tat 3.20605942472665e-05 at epoch 3\n",
    "- also good: 0.77777 at 3.2759208826863756e-05 at epoch 3\n",
    "- 0.726496 at  2.9592151393562346e-05 at epoch 3\n",
    "- 0.752137\t3.443498945690748e-05 at epoch 3\n",
    "\n",
    "7th run:\n",
    "- batch sizes 8\n",
    "- learning_rate between 3.1e-5, 3.4e-5\n",
    "- highest accuracy 0.752137\tat 3.246309190194653e-05 at epoch 3\n",
    "- and at 3.186004390546374e-05 at epoch 2\n",
    "\n",
    "8th run:\n",
    "- batch sizes 8\n",
    "- learning_rate between 1e-5, 1.5e-5\n",
    "- highest accuracy 0.69\tat 1.25e-5 at epoch 5\n"
   ],
   "id": "383a0eb6156887d1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(torch.backends.mps.is_available())\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "conn  = sqlite3.connect('../../giicg.db')\n",
    "prompts = pd.read_sql(\"Select * from expanded_roberta_prompts\", conn)\n",
    "conn.close()\n",
    "prompts"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build dataset\n",
    "- group aware split: no prompts from the same user will occur in both sets\n",
    "- build dataset in huggingface format"
   ],
   "id": "a59370d6a362e2a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from datasets import Dataset\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=42)\n",
    "groups = prompts['user_id']\n",
    "\n",
    "train_idx, val_idx = next(gss.split(prompts, groups=groups))\n",
    "train_prompts = prompts.iloc[train_idx]\n",
    "val_prompts = prompts.iloc[val_idx]\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_prompts[['conversational', 'label']])\n",
    "val_dataset = Dataset.from_pandas(val_prompts[['conversational', 'label']])\n",
    "\n",
    "train_dataset"
   ],
   "id": "e6656aca97d48e7e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model, Tokenizer & Data Collator",
   "id": "ad67dc20150549e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T12:32:41.935657Z",
     "start_time": "2025-09-13T12:32:37.629302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "with open(\"finetune/label2id.json\", \"r\") as f:\n",
    "    label2id = json.load(f)\n",
    "\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "num_labels = len(label2id)\n",
    "\n",
    "def model_init():\n",
    "    # Needed for Trainer's hyperparameter search to re-initialize the model each trial\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=num_labels\n",
    "    )\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"conversational\"],\n",
    "        truncation=True,\n",
    "        padding=False # padding is handled in the data collator\n",
    "    )\n"
   ],
   "id": "4b46658baaf15757",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'label2id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      4\u001B[39m model_name = \u001B[33m\"\u001B[39m\u001B[33mroberta-base\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      5\u001B[39m tokenizer = AutoTokenizer.from_pretrained(model_name)\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m num_labels = \u001B[38;5;28mlen\u001B[39m(\u001B[43mlabel2id\u001B[49m)\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mmodel_init\u001B[39m():\n\u001B[32m      9\u001B[39m     \u001B[38;5;66;03m# Needed for Trainer's hyperparameter search to re-initialize your model each trial\u001B[39;00m\n\u001B[32m     10\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m AutoModelForSequenceClassification.from_pretrained(\n\u001B[32m     11\u001B[39m         model_name,\n\u001B[32m     12\u001B[39m         num_labels=num_labels\n\u001B[32m     13\u001B[39m     )\n",
      "\u001B[31mNameError\u001B[39m: name 'label2id' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenize",
   "id": "a831342d6241ecc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset"
   ],
   "id": "809bd678cccb23b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Trainer",
   "id": "5e7b4e031590dded"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    precision = precision_score(labels, preds, average='weighted')\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=3.2e-5,\n",
    "    #weight_decay= #\n",
    "    #warmup_steps = 10,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    logging_steps=50,\n",
    "    logging_strategy=\"steps\",\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n"
   ],
   "id": "83d5397129784e4f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Search",
   "id": "8c31635d7eecfda5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1.5e-5, log=True),\n",
    "    }\n",
    "\n",
    "\n",
    "best_run = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    hp_space=hp_space,\n",
    "    n_trials=10,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_accuracy\"]\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters:\", best_run.hyperparameters)\n",
    "print(\"Best eval accuracy:\", best_run.objective)\n"
   ],
   "id": "bfc40c5db69d321e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
