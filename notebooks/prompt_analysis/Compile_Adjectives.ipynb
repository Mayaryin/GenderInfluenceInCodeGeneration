{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Compile all present adjectives in the prompts\n",
    "\n",
    "extraxted using spacy\n",
    "saved to txt\n",
    "manually cleaned"
   ],
   "id": "64672688d5d35b5f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-10T13:26:44.633410Z",
     "start_time": "2025-09-10T13:26:43.114671Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from helpers.occurences import count_occurrences, count_punctuation\n",
    "from helpers.statistical_tests import run_t_test_on_gender\n",
    "\n",
    "db_path = \"../../giicg.db\"\n",
    "if not os.path.exists(db_path):\n",
    "    raise FileNotFoundError(f\"Database file does not exist: {db_path}\")\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "prompts = pd.read_sql(\"SELECT * FROM main.expanded_prompts\", conn)\n",
    "prompts = prompts.dropna(subset=['conversational'])\n",
    "prompts = prompts[prompts['conversational'].str.strip() != '']\n",
    "prompts = prompts.dropna(subset=['conversational'])\n",
    "\n",
    "full_text = ' '.join(prompts['conversational'].tolist()).lower()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extract adjectives",
   "id": "ea5f1b18447dc5bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T13:36:52.337984Z",
     "start_time": "2025-09-10T13:36:49.487436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(full_text)\n",
    "\n",
    "adjectives_base = []\n",
    "adjectives_comp = []\n",
    "adjectives_super = []\n",
    "\n",
    "for token in doc:\n",
    "    if token.pos_ == \"ADJ\":\n",
    "        if token.morph.get(\"Degree\") == [\"Pos\"]:\n",
    "            adjectives_base.append(token.lemma_)\n",
    "        elif token.morph.get(\"Degree\") == [\"Cmp\"]:\n",
    "            adjectives_comp.append(token.text)\n",
    "        elif token.morph.get(\"Degree\") == [\"Sup\"]:\n",
    "            adjectives_super.append(token.text)\n",
    "\n",
    "\n",
    "adjectives_base = sorted(set(adjectives_base))\n",
    "adjectives_comp = sorted(set(adjectives_comp))\n",
    "adjectives_super = sorted(set(adjectives_super))\n",
    "\n",
    "print(\"Base form adjectives:\", adjectives_base)\n",
    "print(\"Comparative adjectives:\", adjectives_comp)\n",
    "print(\"Superlative adjectives:\", adjectives_super)\n",
    "\n",
    "with open(\"adjectives_base.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for word in adjectives_base:\n",
    "        f.write(f\"{word}\\n\")\n",
    "\n",
    "with open(\"adjectives_comparative.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for word in adjectives_comp:\n",
    "        f.write(f\"{word}\\n\")\n",
    "\n",
    "with open(\"adjectives_superlative.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for word in adjectives_super:\n",
    "        f.write(f\"{word}\\n\")\n",
    "\n"
   ],
   "id": "2dc1df7256d986ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base form adjectives: ['-', '0px', '=', '\\\\setcounter{subfigures}{3', 'able', 'about', 'above', 'absolute', 'accurate', 'actual', 'additional', 'additonal', 'alleged', 'amazing', 'analytical', 'anomalous', 'apktool', 'appropriate', 'attached', 'audio', 'automated', 'available', 'average', 'axis', 'bad', 'balanced', 'basic', 'biased', 'binary', 'black', 'blue', 'bmesh', 'bold', 'bound', 'brief', 'bright', 'categorical', 'centroid', 'certain', 'circular', 'classic', 'clean', 'clear', 'clicked', 'clustering', 'colored', 'comfortable', 'compact', 'complete', 'complicated', 'computed', 'concrete', 'confused', 'convolutional', 'cool', 'copyable', 'correct', 'current', 'dataframe', 'decent', 'decimal', 'deserialization', 'different', 'difficult', 'discrete', 'distinct', 'dominant', 'double', 'dull', 'dummy', 'dynamic', 'eable', 'early', 'easy', 'efficient', 'elegant', 'embarked_c', 'encode', 'enough', 'entire', 'equal', 'excessive', 'expand', 'expected', 'f1', 'faiss', 'false', 'fetchtable', 'few', 'final', 'fine', 'firefox', 'first', 'fit', 'following', 'font', 'former', 'frequent', 'full', 'functioning', 'funny', 'further', 'g', 'gaussian', 'general', 'global', 'good', 'gradient', 'gravitational', 'great', 'green', 'h2', 'happy', 'hard', 'hi', 'hidden', 'high', 'hot', 'hover', 'i', 'identical', 'iframe', 'ill', 'immediate', 'important', 'incoming', 'initial', 'insert', 'intense', 'interactive', 'interested', 'intermediate', 'invalid', 'iterative', 'javascript', 'jit', 'jupyter', 'key', 'large', 'last', 'left', 'lightrag', 'likely', 'linspace', 'little', 'llama', 'local', 'long', 'main', 'major', 'manipulated', 'manual', 'many', 'maximum', 'mean', 'metrical', 'minimal', 'minor', 'mistaken', 'mixed', 'modal', 'monthly', 'much', 'multiple', 'necessary', 'neet', 'nested', 'neuemageritalic', 'neuemagic', 'neuenormal', 'new', 'next', 'nice', 'non', 'numeric', 'numerical', 'nunito', 'observable', 'offline', 'ok', 'okay', 'oklab', 'old', 'only', 'openmodal', 'optimal', 'original', 'orthogonal', 'other', 'over', 'overall', 'own', 'passengerid', 'perpendicular', 'pink', 'pixel', 'pointless', 'possible', 'previous', 'primordial', 'principal', 'probable', 'purple', 'pydantic', 'random', 'randomly', 'raw', 'reachable', 'red', 'related', 'relative', 'relevant', 'rename', 'reset', 'responsible', 'reusable', 'rgb', 'right', 'rl', 'safe', 'same', 'saturated', 'scalar', 'scarlet', 'scrollable', 'second', 'separate', 'several', 'shitty', 'short', 'significant', 'similar', 'simple', 'single', 'sized', 'skip', 'sl', 'slight', 'small', 'smart', 'sorry', 'sound', 'special', 'specific', 'specified', 'sql', 'standard', 'statistical', 'still', 'straight', 'strong', 'such', 'suitable', 'sure', 'svelteflow', 'sweeping', 'tedious', 'temporal', 'third', 'timeslot', 'titanic', 'top', 'train_filenames.npy', 'transparent', 'true', 'trustworthy', 'tsne', 'ugly', 'unbalanced', 'unchanged', 'undefined', 'understandable', 'unified', 'unique', 'unmanipluated', 'unmanipulated', 'usual', 'valid', 'validate', 'variable', 'visual', 'walter', 'weighted', 'weird', 'white', 'whole', 'wise', 'worth', 'wrong', 'yearly']\n",
      "Comparative adjectives: ['better', 'bigger', 'cheaper', 'closer', 'earlier', 'easier', 'faster', 'higher', 'larger', 'lower', 'more', 'newer', 'outlier', 'quicker', 'smaller', 'tougher', 'worse']\n",
      "Superlative adjectives: ['best', 'easiest', 'shortest']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "19a2c14fe21d9e1a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
