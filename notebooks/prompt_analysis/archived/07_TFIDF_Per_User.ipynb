{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-02T13:32:11.498045Z",
     "start_time": "2025-10-02T13:32:11.468205Z"
    }
   },
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('../../../giicg.db')\n",
    "\n",
    "prompts = pd.read_sql(\"SELECT * FROM expanded_roberta_prompts\", conn)\n",
    "conn.close()\n",
    "prompts"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     level_0  index  message_id  conversation_id  role  \\\n",
       "0          0      0           1                1  user   \n",
       "1          1      1         730               32  user   \n",
       "2          2      2        1133               55  user   \n",
       "3          3      3        1135               55  user   \n",
       "4          4      4        1137               55  user   \n",
       "..       ...    ...         ...              ...   ...   \n",
       "531      531    501        1674               87  user   \n",
       "532      532    416        1290               65  user   \n",
       "533      533    425        1314               65  user   \n",
       "534      534    309         372               21  user   \n",
       "535      535    503        1678               87  user   \n",
       "\n",
       "                                          message_text  \\\n",
       "0    parsing data from python iterator, how it coul...   \n",
       "1    Write python function to do operations with in...   \n",
       "2    Write shortest tutorial on creating RAG on ema...   \n",
       "3                                        what is FAISS   \n",
       "4     Transform given code to process large .mbox file   \n",
       "..                                                 ...   \n",
       "531  Accuracy: 1.0\\n  Count: 2\\nMetrics for neptune...   \n",
       "532  how are we currently processing non numerical ...   \n",
       "533                     what is the reachability score   \n",
       "534  my features are saved in \"train_features.npy\" ...   \n",
       "535  great now please move more stuff from main to ...   \n",
       "\n",
       "                                        conversational  \\\n",
       "0    parsing data from python iterator, how it coul...   \n",
       "1    Write python function to do operations with in...   \n",
       "2    Write shortest tutorial on creating RAG on ema...   \n",
       "3                                        what is FAISS   \n",
       "4     Transform given code to process large .mbox file   \n",
       "..                                                 ...   \n",
       "531  these are the results. i to calculate a statis...   \n",
       "532  how are we currently processing non numerical ...   \n",
       "533                     what is the reachability score   \n",
       "534  my features are saved in \"train_features.npy\" ...   \n",
       "535  great now please move more stuff from main to ...   \n",
       "\n",
       "                                                  code  \\\n",
       "0                                                        \n",
       "1                                                        \n",
       "2                                                        \n",
       "3                                                        \n",
       "4                                                        \n",
       "..                                                 ...   \n",
       "531                                                      \n",
       "532  def perform_optics_clustering(file_path, outpu...   \n",
       "533                                                      \n",
       "534                                                      \n",
       "535                                                      \n",
       "\n",
       "                                                 other             gender  \\\n",
       "0                                                         Man (cisgender)   \n",
       "1    report_dt\\tsource\\tmetric_name\\tmetric_num\\tme...    Man (cisgender)   \n",
       "2                                                         Man (cisgender)   \n",
       "3                                                         Man (cisgender)   \n",
       "4     Transform given code to process large .mbox file    Man (cisgender)   \n",
       "..                                                 ...                ...   \n",
       "531  Accuracy: 1.0\\n  Count: 2\\nMetrics for neptune...  Woman (cisgender)   \n",
       "532                                                     Woman (cisgender)   \n",
       "533                                                     Woman (cisgender)   \n",
       "534                                                     Woman (cisgender)   \n",
       "535                                                     Woman (cisgender)   \n",
       "\n",
       "     user_id language  label  \\\n",
       "0          6       en      0   \n",
       "1          6       en      0   \n",
       "2          6       en      0   \n",
       "3          6       en      0   \n",
       "4          6       en      0   \n",
       "..       ...      ...    ...   \n",
       "531       73       en      1   \n",
       "532       73       en      1   \n",
       "533       73       en      1   \n",
       "534       73       en      1   \n",
       "535       73       en      1   \n",
       "\n",
       "                                         masked_prompt  \\\n",
       "0    parsing data from [TERM], how it could be hand...   \n",
       "1    Write python function to do operations with in...   \n",
       "2    Write shortest tutorial on creating [TERM] on ...   \n",
       "3                                       what is [TERM]   \n",
       "4    Transform given code to process large [TERM] file   \n",
       "..                                                 ...   \n",
       "531  [INFO]\\n[INFO]\\n[TERM]:\\n  [TERM]: [OTHER]\\n  ...   \n",
       "532  how are we currently processing non numerical ...   \n",
       "533                                 what is the [TERM]   \n",
       "534  my features are saved in [TERM] and the file n...   \n",
       "535  great now please move more stuff from main to ...   \n",
       "\n",
       "                                     masked_translated  \n",
       "0    parsing data from [TERM], how it could be hand...  \n",
       "1    Write python function to do operations with in...  \n",
       "2    Write shortest tutorial on creating [TERM] on ...  \n",
       "3                                       what is [TERM]  \n",
       "4    Transform given code to process large [TERM] file  \n",
       "..                                                 ...  \n",
       "531  [INFO]\\n[INFO]\\n[TERM]:\\n  [TERM]: [OTHER]\\n  ...  \n",
       "532  how are we currently processing non numerical ...  \n",
       "533                                 what is the [TERM]  \n",
       "534  my features are saved in [TERM] and the file n...  \n",
       "535  great now please move more stuff from main to ...  \n",
       "\n",
       "[536 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>message_id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>role</th>\n",
       "      <th>message_text</th>\n",
       "      <th>conversational</th>\n",
       "      <th>code</th>\n",
       "      <th>other</th>\n",
       "      <th>gender</th>\n",
       "      <th>user_id</th>\n",
       "      <th>language</th>\n",
       "      <th>label</th>\n",
       "      <th>masked_prompt</th>\n",
       "      <th>masked_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>parsing data from python iterator, how it coul...</td>\n",
       "      <td>parsing data from python iterator, how it coul...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>parsing data from [TERM], how it could be hand...</td>\n",
       "      <td>parsing data from [TERM], how it could be hand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>730</td>\n",
       "      <td>32</td>\n",
       "      <td>user</td>\n",
       "      <td>Write python function to do operations with in...</td>\n",
       "      <td>Write python function to do operations with in...</td>\n",
       "      <td></td>\n",
       "      <td>report_dt\\tsource\\tmetric_name\\tmetric_num\\tme...</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>Write python function to do operations with in...</td>\n",
       "      <td>Write python function to do operations with in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1133</td>\n",
       "      <td>55</td>\n",
       "      <td>user</td>\n",
       "      <td>Write shortest tutorial on creating RAG on ema...</td>\n",
       "      <td>Write shortest tutorial on creating RAG on ema...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>Write shortest tutorial on creating [TERM] on ...</td>\n",
       "      <td>Write shortest tutorial on creating [TERM] on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1135</td>\n",
       "      <td>55</td>\n",
       "      <td>user</td>\n",
       "      <td>what is FAISS</td>\n",
       "      <td>what is FAISS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>what is [TERM]</td>\n",
       "      <td>what is [TERM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1137</td>\n",
       "      <td>55</td>\n",
       "      <td>user</td>\n",
       "      <td>Transform given code to process large .mbox file</td>\n",
       "      <td>Transform given code to process large .mbox file</td>\n",
       "      <td></td>\n",
       "      <td>Transform given code to process large .mbox file</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>Transform given code to process large [TERM] file</td>\n",
       "      <td>Transform given code to process large [TERM] file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>531</td>\n",
       "      <td>501</td>\n",
       "      <td>1674</td>\n",
       "      <td>87</td>\n",
       "      <td>user</td>\n",
       "      <td>Accuracy: 1.0\\n  Count: 2\\nMetrics for neptune...</td>\n",
       "      <td>these are the results. i to calculate a statis...</td>\n",
       "      <td></td>\n",
       "      <td>Accuracy: 1.0\\n  Count: 2\\nMetrics for neptune...</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>73</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>[INFO]\\n[INFO]\\n[TERM]:\\n  [TERM]: [OTHER]\\n  ...</td>\n",
       "      <td>[INFO]\\n[INFO]\\n[TERM]:\\n  [TERM]: [OTHER]\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>532</td>\n",
       "      <td>416</td>\n",
       "      <td>1290</td>\n",
       "      <td>65</td>\n",
       "      <td>user</td>\n",
       "      <td>how are we currently processing non numerical ...</td>\n",
       "      <td>how are we currently processing non numerical ...</td>\n",
       "      <td>def perform_optics_clustering(file_path, outpu...</td>\n",
       "      <td></td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>73</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>how are we currently processing non numerical ...</td>\n",
       "      <td>how are we currently processing non numerical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>533</td>\n",
       "      <td>425</td>\n",
       "      <td>1314</td>\n",
       "      <td>65</td>\n",
       "      <td>user</td>\n",
       "      <td>what is the reachability score</td>\n",
       "      <td>what is the reachability score</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>73</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>what is the [TERM]</td>\n",
       "      <td>what is the [TERM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>534</td>\n",
       "      <td>309</td>\n",
       "      <td>372</td>\n",
       "      <td>21</td>\n",
       "      <td>user</td>\n",
       "      <td>my features are saved in \"train_features.npy\" ...</td>\n",
       "      <td>my features are saved in \"train_features.npy\" ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>73</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>my features are saved in [TERM] and the file n...</td>\n",
       "      <td>my features are saved in [TERM] and the file n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>535</td>\n",
       "      <td>503</td>\n",
       "      <td>1678</td>\n",
       "      <td>87</td>\n",
       "      <td>user</td>\n",
       "      <td>great now please move more stuff from main to ...</td>\n",
       "      <td>great now please move more stuff from main to ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>73</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>great now please move more stuff from main to ...</td>\n",
       "      <td>great now please move more stuff from main to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 15 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T13:32:11.561960Z",
     "start_time": "2025-10-02T13:32:11.554696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from helpers.normalization import remove_punctuation_and_newlines, remove_capitalization\n",
    "\n",
    "#prompts['masked_translated'] = prompts['masked_translated'].apply(remove_punctuation_and_newlines)\n",
    "#prompts['masked_translated'] = prompts['masked_translated'].apply(remove_capitalization)\n",
    "\n",
    "prompts"
   ],
   "id": "f21437f02dc7092a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     level_0  index  message_id  conversation_id  role  \\\n",
       "0          0      0           1                1  user   \n",
       "1          1      1         730               32  user   \n",
       "2          2      2        1133               55  user   \n",
       "3          3      3        1135               55  user   \n",
       "4          4      4        1137               55  user   \n",
       "..       ...    ...         ...              ...   ...   \n",
       "531      531    501        1674               87  user   \n",
       "532      532    416        1290               65  user   \n",
       "533      533    425        1314               65  user   \n",
       "534      534    309         372               21  user   \n",
       "535      535    503        1678               87  user   \n",
       "\n",
       "                                          message_text  \\\n",
       "0    parsing data from python iterator, how it coul...   \n",
       "1    Write python function to do operations with in...   \n",
       "2    Write shortest tutorial on creating RAG on ema...   \n",
       "3                                        what is FAISS   \n",
       "4     Transform given code to process large .mbox file   \n",
       "..                                                 ...   \n",
       "531  Accuracy: 1.0\\n  Count: 2\\nMetrics for neptune...   \n",
       "532  how are we currently processing non numerical ...   \n",
       "533                     what is the reachability score   \n",
       "534  my features are saved in \"train_features.npy\" ...   \n",
       "535  great now please move more stuff from main to ...   \n",
       "\n",
       "                                        conversational  \\\n",
       "0    parsing data from python iterator, how it coul...   \n",
       "1    Write python function to do operations with in...   \n",
       "2    Write shortest tutorial on creating RAG on ema...   \n",
       "3                                        what is FAISS   \n",
       "4     Transform given code to process large .mbox file   \n",
       "..                                                 ...   \n",
       "531  these are the results. i to calculate a statis...   \n",
       "532  how are we currently processing non numerical ...   \n",
       "533                     what is the reachability score   \n",
       "534  my features are saved in \"train_features.npy\" ...   \n",
       "535  great now please move more stuff from main to ...   \n",
       "\n",
       "                                                  code  \\\n",
       "0                                                        \n",
       "1                                                        \n",
       "2                                                        \n",
       "3                                                        \n",
       "4                                                        \n",
       "..                                                 ...   \n",
       "531                                                      \n",
       "532  def perform_optics_clustering(file_path, outpu...   \n",
       "533                                                      \n",
       "534                                                      \n",
       "535                                                      \n",
       "\n",
       "                                                 other             gender  \\\n",
       "0                                                         Man (cisgender)   \n",
       "1    report_dt\\tsource\\tmetric_name\\tmetric_num\\tme...    Man (cisgender)   \n",
       "2                                                         Man (cisgender)   \n",
       "3                                                         Man (cisgender)   \n",
       "4     Transform given code to process large .mbox file    Man (cisgender)   \n",
       "..                                                 ...                ...   \n",
       "531  Accuracy: 1.0\\n  Count: 2\\nMetrics for neptune...  Woman (cisgender)   \n",
       "532                                                     Woman (cisgender)   \n",
       "533                                                     Woman (cisgender)   \n",
       "534                                                     Woman (cisgender)   \n",
       "535                                                     Woman (cisgender)   \n",
       "\n",
       "     user_id language  label  \\\n",
       "0          6       en      0   \n",
       "1          6       en      0   \n",
       "2          6       en      0   \n",
       "3          6       en      0   \n",
       "4          6       en      0   \n",
       "..       ...      ...    ...   \n",
       "531       73       en      1   \n",
       "532       73       en      1   \n",
       "533       73       en      1   \n",
       "534       73       en      1   \n",
       "535       73       en      1   \n",
       "\n",
       "                                         masked_prompt  \\\n",
       "0    parsing data from [TERM], how it could be hand...   \n",
       "1    Write python function to do operations with in...   \n",
       "2    Write shortest tutorial on creating [TERM] on ...   \n",
       "3                                       what is [TERM]   \n",
       "4    Transform given code to process large [TERM] file   \n",
       "..                                                 ...   \n",
       "531  [INFO]\\n[INFO]\\n[TERM]:\\n  [TERM]: [OTHER]\\n  ...   \n",
       "532  how are we currently processing non numerical ...   \n",
       "533                                 what is the [TERM]   \n",
       "534  my features are saved in [TERM] and the file n...   \n",
       "535  great now please move more stuff from main to ...   \n",
       "\n",
       "                                     masked_translated  \n",
       "0    parsing data from [TERM], how it could be hand...  \n",
       "1    Write python function to do operations with in...  \n",
       "2    Write shortest tutorial on creating [TERM] on ...  \n",
       "3                                       what is [TERM]  \n",
       "4    Transform given code to process large [TERM] file  \n",
       "..                                                 ...  \n",
       "531  [INFO]\\n[INFO]\\n[TERM]:\\n  [TERM]: [OTHER]\\n  ...  \n",
       "532  how are we currently processing non numerical ...  \n",
       "533                                 what is the [TERM]  \n",
       "534  my features are saved in [TERM] and the file n...  \n",
       "535  great now please move more stuff from main to ...  \n",
       "\n",
       "[536 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>message_id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>role</th>\n",
       "      <th>message_text</th>\n",
       "      <th>conversational</th>\n",
       "      <th>code</th>\n",
       "      <th>other</th>\n",
       "      <th>gender</th>\n",
       "      <th>user_id</th>\n",
       "      <th>language</th>\n",
       "      <th>label</th>\n",
       "      <th>masked_prompt</th>\n",
       "      <th>masked_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>parsing data from python iterator, how it coul...</td>\n",
       "      <td>parsing data from python iterator, how it coul...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>parsing data from [TERM], how it could be hand...</td>\n",
       "      <td>parsing data from [TERM], how it could be hand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>730</td>\n",
       "      <td>32</td>\n",
       "      <td>user</td>\n",
       "      <td>Write python function to do operations with in...</td>\n",
       "      <td>Write python function to do operations with in...</td>\n",
       "      <td></td>\n",
       "      <td>report_dt\\tsource\\tmetric_name\\tmetric_num\\tme...</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>Write python function to do operations with in...</td>\n",
       "      <td>Write python function to do operations with in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1133</td>\n",
       "      <td>55</td>\n",
       "      <td>user</td>\n",
       "      <td>Write shortest tutorial on creating RAG on ema...</td>\n",
       "      <td>Write shortest tutorial on creating RAG on ema...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>Write shortest tutorial on creating [TERM] on ...</td>\n",
       "      <td>Write shortest tutorial on creating [TERM] on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1135</td>\n",
       "      <td>55</td>\n",
       "      <td>user</td>\n",
       "      <td>what is FAISS</td>\n",
       "      <td>what is FAISS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>what is [TERM]</td>\n",
       "      <td>what is [TERM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1137</td>\n",
       "      <td>55</td>\n",
       "      <td>user</td>\n",
       "      <td>Transform given code to process large .mbox file</td>\n",
       "      <td>Transform given code to process large .mbox file</td>\n",
       "      <td></td>\n",
       "      <td>Transform given code to process large .mbox file</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>Transform given code to process large [TERM] file</td>\n",
       "      <td>Transform given code to process large [TERM] file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>531</td>\n",
       "      <td>501</td>\n",
       "      <td>1674</td>\n",
       "      <td>87</td>\n",
       "      <td>user</td>\n",
       "      <td>Accuracy: 1.0\\n  Count: 2\\nMetrics for neptune...</td>\n",
       "      <td>these are the results. i to calculate a statis...</td>\n",
       "      <td></td>\n",
       "      <td>Accuracy: 1.0\\n  Count: 2\\nMetrics for neptune...</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>73</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>[INFO]\\n[INFO]\\n[TERM]:\\n  [TERM]: [OTHER]\\n  ...</td>\n",
       "      <td>[INFO]\\n[INFO]\\n[TERM]:\\n  [TERM]: [OTHER]\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>532</td>\n",
       "      <td>416</td>\n",
       "      <td>1290</td>\n",
       "      <td>65</td>\n",
       "      <td>user</td>\n",
       "      <td>how are we currently processing non numerical ...</td>\n",
       "      <td>how are we currently processing non numerical ...</td>\n",
       "      <td>def perform_optics_clustering(file_path, outpu...</td>\n",
       "      <td></td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>73</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>how are we currently processing non numerical ...</td>\n",
       "      <td>how are we currently processing non numerical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>533</td>\n",
       "      <td>425</td>\n",
       "      <td>1314</td>\n",
       "      <td>65</td>\n",
       "      <td>user</td>\n",
       "      <td>what is the reachability score</td>\n",
       "      <td>what is the reachability score</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>73</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>what is the [TERM]</td>\n",
       "      <td>what is the [TERM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>534</td>\n",
       "      <td>309</td>\n",
       "      <td>372</td>\n",
       "      <td>21</td>\n",
       "      <td>user</td>\n",
       "      <td>my features are saved in \"train_features.npy\" ...</td>\n",
       "      <td>my features are saved in \"train_features.npy\" ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>73</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>my features are saved in [TERM] and the file n...</td>\n",
       "      <td>my features are saved in [TERM] and the file n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>535</td>\n",
       "      <td>503</td>\n",
       "      <td>1678</td>\n",
       "      <td>87</td>\n",
       "      <td>user</td>\n",
       "      <td>great now please move more stuff from main to ...</td>\n",
       "      <td>great now please move more stuff from main to ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>73</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>great now please move more stuff from main to ...</td>\n",
       "      <td>great now please move more stuff from main to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 15 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T13:32:11.642123Z",
     "start_time": "2025-10-02T13:32:11.632030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_prompts = (\n",
    "    prompts.groupby(['user_id', 'gender'])['masked_translated']\n",
    "    .apply(' '.join)\n",
    "    .reset_index()    # Reset index to create a DataFrame\n",
    ")\n",
    "\n",
    "user_prompts.columns = ['user_id', 'gender', 'combined_prompts']\n",
    "user_prompts = user_prompts[user_prompts['gender'].isin(['Woman (cisgender)', 'Man (cisgender)'])].reset_index()\n",
    "\n",
    "user_prompts"
   ],
   "id": "719321189607229b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    index  user_id             gender  \\\n",
       "0       0        6    Man (cisgender)   \n",
       "1       1        8    Man (cisgender)   \n",
       "2       2       11  Woman (cisgender)   \n",
       "3       3       15    Man (cisgender)   \n",
       "4       4       16  Woman (cisgender)   \n",
       "5       5       25    Man (cisgender)   \n",
       "6       6       28  Woman (cisgender)   \n",
       "7       7       29  Woman (cisgender)   \n",
       "8       8       31    Man (cisgender)   \n",
       "9       9       34    Man (cisgender)   \n",
       "10     10       46    Man (cisgender)   \n",
       "11     11       47    Man (cisgender)   \n",
       "12     12       48  Woman (cisgender)   \n",
       "13     13       55  Woman (cisgender)   \n",
       "14     14       56    Man (cisgender)   \n",
       "15     15       60  Woman (cisgender)   \n",
       "16     16       63  Woman (cisgender)   \n",
       "17     17       65  Woman (cisgender)   \n",
       "18     18       73  Woman (cisgender)   \n",
       "19     19       77    Man (cisgender)   \n",
       "20     20       79  Woman (cisgender)   \n",
       "21     21       81    Man (cisgender)   \n",
       "22     22       83    Man (cisgender)   \n",
       "23     23       88    Man (cisgender)   \n",
       "24     24       89  Woman (cisgender)   \n",
       "25     25       90  Woman (cisgender)   \n",
       "26     26       91    Man (cisgender)   \n",
       "27     27       92    Man (cisgender)   \n",
       "\n",
       "                                     combined_prompts  \n",
       "0   parsing data from [TERM], how it could be hand...  \n",
       "1   I am working on the problem of reconstruction ...  \n",
       "2   Can you adapt the following code so that inste...  \n",
       "3   [TERM] action is currently not fetching them p...  \n",
       "4   I want to use [TERM] encoding to replace the v...  \n",
       "5   whats the best way to encode and compress a [T...  \n",
       "6   I have a [INFO]\\n\\nI want to extract the perso...  \n",
       "7   Now I want to bring [TERM] into this graph. in...  \n",
       "8   How can I make use of an [TERM]?\\n\\nI get this...  \n",
       "9   Blender and Python. I have a collection of hun...  \n",
       "10  how to run a [TERM] without blocking, i.e. onl...  \n",
       "11  can you create [TERM] scripts? in which format...  \n",
       "12  hey can you write me a short python script for...  \n",
       "13  [CODE]\\nPatients\\n CT\\n MRI\\n WSI\\n Genomics\\n...  \n",
       "14  # Output where the containerized service will ...  \n",
       "15  how can I merge two [TERM] files into jupyter ...  \n",
       "16  [CODE]\\n\\ncan you give me a new code snippet w...  \n",
       "17  I work with Python and have to read a [TERM] f...  \n",
       "18  now it is rounded but there are still zeros pr...  \n",
       "19  I have this function that is supposed to perfo...  \n",
       "20  [CODE] From here you could zero all values tha...  \n",
       "21  I have a programming project and need help: Th...  \n",
       "22  Implement [TERM] much closer to the way it is ...  \n",
       "23  in my [TERM] i have an [TERM] that is dynamica...  \n",
       "24  are there paper where these metrics were first...  \n",
       "25  is there a way to get the object key in here?\\...  \n",
       "26  Hey, I'm writing an application. Because I wan...  \n",
       "27  Please replace my retrieval pipeline here with...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>combined_prompts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>parsing data from [TERM], how it could be hand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>I am working on the problem of reconstruction ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>Can you adapt the following code so that inste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>[TERM] action is currently not fetching them p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>I want to use [TERM] encoding to replace the v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>whats the best way to encode and compress a [T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>I have a [INFO]\\n\\nI want to extract the perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>Now I want to bring [TERM] into this graph. in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>How can I make use of an [TERM]?\\n\\nI get this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>Blender and Python. I have a collection of hun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>how to run a [TERM] without blocking, i.e. onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>can you create [TERM] scripts? in which format...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>hey can you write me a short python script for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>55</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>[CODE]\\nPatients\\n CT\\n MRI\\n WSI\\n Genomics\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>56</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td># Output where the containerized service will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>how can I merge two [TERM] files into jupyter ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>63</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>[CODE]\\n\\ncan you give me a new code snippet w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>65</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>I work with Python and have to read a [TERM] f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>73</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>now it is rounded but there are still zeros pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>77</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>I have this function that is supposed to perfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>79</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>[CODE] From here you could zero all values tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>81</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>I have a programming project and need help: Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>83</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>Implement [TERM] much closer to the way it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>88</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>in my [TERM] i have an [TERM] that is dynamica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>89</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>are there paper where these metrics were first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>90</td>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>is there a way to get the object key in here?\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>91</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>Hey, I'm writing an application. Because I wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>92</td>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>Please replace my retrieval pipeline here with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T13:32:17.883648Z",
     "start_time": "2025-10-02T13:32:11.742137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TF-IDF + Stratified 5-fold CV for Logistic Regression and Linear SVM\n",
    "# Assumes `user_prompts` DataFrame (with columns 'combined_prompts' and 'gender') is already in the notebook.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, cross_val_predict\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Prepare X, y\n",
    "X = user_prompts['combined_prompts'].values\n",
    "# Map labels to binary integers (adjust mapping if you want reverse)\n",
    "label_map = {'Woman (cisgender)': 0, 'Man (cisgender)': 1}\n",
    "y = user_prompts['gender'].map(label_map).values\n",
    "\n",
    "# Stratified 5-fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "\n",
    "# TF-IDF vectorizer settings (tweak as needed)\n",
    "tfidf_kwargs = dict(\n",
    "    max_features=500,\n",
    "    ngram_range=(1, 2),\n",
    "    #stop_words='english',\n",
    "    stop_words=[\"[TERM]\", \"[CODE]\", \"[ERROR]\", \"[URL]\", \"[INFO]\", \"[ID]\", \"[OTHER]\"],\n",
    "    #stop_words=['of', 'to', 'is', 'in', 'and', 'that', 'it'],\n",
    "    #stop_words=['can', 'and', 'you', 'me', 'this', 'that', 'please'],\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "# Pipelines\n",
    "pipe_lr = make_pipeline(\n",
    "    TfidfVectorizer(**tfidf_kwargs),\n",
    "    LogisticRegression(max_iter=2000, solver='liblinear', random_state=42)\n",
    ")\n",
    "\n",
    "pipe_svm = make_pipeline(\n",
    "    TfidfVectorizer(**tfidf_kwargs),\n",
    "    LinearSVC(random_state=42)\n",
    ")\n",
    "\n",
    "# Cross-validated metrics (fits TF-IDF only on training folds automatically)\n",
    "cv_results_lr = cross_validate(pipe_lr, X, y, cv=skf, scoring=scoring, n_jobs=-1, return_train_score=False, return_estimator=True)\n",
    "cv_results_svm = cross_validate(pipe_svm, X, y, cv=skf, scoring=scoring, n_jobs=-1, return_train_score=False, return_estimator=True)\n",
    "\n",
    "estimators = list(cv_results_lr['estimator']) + list(cv_results_svm['estimator'])\n",
    " # list of fitted Pipelines, one per fold\n",
    "\n",
    "for i, est in enumerate(estimators):\n",
    "    # find the TfidfVectorizer inside the pipeline robustly\n",
    "    vec = next(v for v in est.named_steps.values() if isinstance(v, TfidfVectorizer))\n",
    "    features = vec.get_feature_names_out()\n",
    "    print(f\"\\nFold {i}: vocab size = {len(features)}\")\n",
    "    idf = vec.idf_\n",
    "    top_common = pd.DataFrame({\"term\": features, \"idf\": idf}).sort_values(\"idf\").head(10)\n",
    "    print(\"Most common (lowest idf) in this fold:\")\n",
    "    print(top_common.to_string(index=False))\n",
    "\n",
    "\n",
    "\n",
    "def summarize_cv(results, scorer_list=scoring):\n",
    "    for metric in scorer_list:\n",
    "        arr = results[f'test_{metric}']\n",
    "        print(f\"{metric:15s} mean = {arr.mean():.4f}   std = {arr.std():.4f}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "print(\"Logistic Regression (TF-IDF) CV summary\")\n",
    "summarize_cv(cv_results_lr)\n",
    "\n",
    "print(\"Linear SVM (TF-IDF) CV summary\")\n",
    "summarize_cv(cv_results_svm)\n",
    "\n",
    "# Optional: get cross-validated predictions and a classification report (aggregated)\n",
    "y_pred_lr = cross_val_predict(pipe_lr, X, y, cv=skf, n_jobs=-1)\n",
    "y_pred_svm = cross_val_predict(pipe_svm, X, y, cv=skf, n_jobs=-1)\n",
    "\n",
    "print(\"Logistic Regression - classification report (aggregated across folds)\")\n",
    "print(classification_report(y, y_pred_lr, target_names=['Woman (cisgender)', 'Man (cisgender)']))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y, y_pred_lr))\n",
    "\n",
    "print(\"\\nLinear SVM - classification report (aggregated across folds)\")\n",
    "print(classification_report(y, y_pred_svm, target_names=['Woman (cisgender)', 'Man (cisgender)']))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y, y_pred_svm))"
   ],
   "id": "505601fc29b53568",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0: vocab size = 500\n",
      "Most common (lowest idf) in this fold:\n",
      "term      idf\n",
      "  to 1.000000\n",
      " the 1.000000\n",
      " and 1.000000\n",
      "  in 1.044452\n",
      "  it 1.044452\n",
      "term 1.044452\n",
      "  is 1.044452\n",
      "code 1.090972\n",
      "  of 1.090972\n",
      "that 1.090972\n",
      "\n",
      "Fold 1: vocab size = 500\n",
      "Most common (lowest idf) in this fold:\n",
      "term      idf\n",
      " the 1.000000\n",
      " and 1.044452\n",
      "  to 1.044452\n",
      "  is 1.090972\n",
      "  of 1.090972\n",
      "term 1.090972\n",
      "that 1.139762\n",
      "  in 1.139762\n",
      "code 1.139762\n",
      "  it 1.191055\n",
      "\n",
      "Fold 2: vocab size = 500\n",
      "Most common (lowest idf) in this fold:\n",
      "term      idf\n",
      " the 1.000000\n",
      "  is 1.044452\n",
      "  to 1.044452\n",
      " and 1.044452\n",
      "  of 1.090972\n",
      "code 1.090972\n",
      "term 1.090972\n",
      "  in 1.139762\n",
      "that 1.139762\n",
      "  it 1.139762\n",
      "\n",
      "Fold 3: vocab size = 500\n",
      "Most common (lowest idf) in this fold:\n",
      "term      idf\n",
      " the 1.000000\n",
      "  to 1.042560\n",
      " and 1.042560\n",
      "  is 1.087011\n",
      "term 1.087011\n",
      "  of 1.133531\n",
      "code 1.133531\n",
      "  in 1.133531\n",
      "  it 1.182322\n",
      "that 1.182322\n",
      "\n",
      "Fold 4: vocab size = 500\n",
      "Most common (lowest idf) in this fold:\n",
      "term      idf\n",
      " the 1.000000\n",
      "  to 1.042560\n",
      " and 1.042560\n",
      "term 1.042560\n",
      "  in 1.087011\n",
      "code 1.087011\n",
      "  is 1.087011\n",
      "  of 1.133531\n",
      "have 1.133531\n",
      "this 1.133531\n",
      "\n",
      "Fold 5: vocab size = 500\n",
      "Most common (lowest idf) in this fold:\n",
      "term      idf\n",
      "  to 1.000000\n",
      " the 1.000000\n",
      " and 1.000000\n",
      "  in 1.044452\n",
      "  it 1.044452\n",
      "term 1.044452\n",
      "  is 1.044452\n",
      "code 1.090972\n",
      "  of 1.090972\n",
      "that 1.090972\n",
      "\n",
      "Fold 6: vocab size = 500\n",
      "Most common (lowest idf) in this fold:\n",
      "term      idf\n",
      " the 1.000000\n",
      " and 1.044452\n",
      "  to 1.044452\n",
      "  is 1.090972\n",
      "  of 1.090972\n",
      "term 1.090972\n",
      "that 1.139762\n",
      "  in 1.139762\n",
      "code 1.139762\n",
      "  it 1.191055\n",
      "\n",
      "Fold 7: vocab size = 500\n",
      "Most common (lowest idf) in this fold:\n",
      "term      idf\n",
      " the 1.000000\n",
      "  is 1.044452\n",
      "  to 1.044452\n",
      " and 1.044452\n",
      "  of 1.090972\n",
      "code 1.090972\n",
      "term 1.090972\n",
      "  in 1.139762\n",
      "that 1.139762\n",
      "  it 1.139762\n",
      "\n",
      "Fold 8: vocab size = 500\n",
      "Most common (lowest idf) in this fold:\n",
      "term      idf\n",
      " the 1.000000\n",
      "  to 1.042560\n",
      " and 1.042560\n",
      "  is 1.087011\n",
      "term 1.087011\n",
      "  of 1.133531\n",
      "code 1.133531\n",
      "  in 1.133531\n",
      "  it 1.182322\n",
      "that 1.182322\n",
      "\n",
      "Fold 9: vocab size = 500\n",
      "Most common (lowest idf) in this fold:\n",
      "term      idf\n",
      " the 1.000000\n",
      "  to 1.042560\n",
      " and 1.042560\n",
      "term 1.042560\n",
      "  in 1.087011\n",
      "code 1.087011\n",
      "  is 1.087011\n",
      "  of 1.133531\n",
      "have 1.133531\n",
      "this 1.133531\n",
      "Logistic Regression (TF-IDF) CV summary\n",
      "accuracy        mean = 0.5733   std = 0.0646\n",
      "precision_macro mean = 0.4867   std = 0.1993\n",
      "recall_macro    mean = 0.5500   std = 0.0667\n",
      "f1_macro        mean = 0.4805   std = 0.1134\n",
      "\n",
      "Linear SVM (TF-IDF) CV summary\n",
      "accuracy        mean = 0.5133   std = 0.1759\n",
      "precision_macro mean = 0.4333   std = 0.2221\n",
      "recall_macro    mean = 0.5000   std = 0.1826\n",
      "f1_macro        mean = 0.4488   std = 0.1913\n",
      "\n",
      "Logistic Regression - classification report (aggregated across folds)\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Woman (cisgender)       0.60      0.23      0.33        13\n",
      "  Man (cisgender)       0.57      0.87      0.68        15\n",
      "\n",
      "         accuracy                           0.57        28\n",
      "        macro avg       0.58      0.55      0.51        28\n",
      "     weighted avg       0.58      0.57      0.52        28\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 3 10]\n",
      " [ 2 13]]\n",
      "\n",
      "Linear SVM - classification report (aggregated across folds)\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Woman (cisgender)       0.44      0.31      0.36        13\n",
      "  Man (cisgender)       0.53      0.67      0.59        15\n",
      "\n",
      "         accuracy                           0.50        28\n",
      "        macro avg       0.49      0.49      0.48        28\n",
      "     weighted avg       0.49      0.50      0.48        28\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 4  9]\n",
      " [ 5 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['code', 'error', 'id', 'info', 'other', 'term', 'url'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T13:32:17.936270Z",
     "start_time": "2025-10-02T13:32:17.934775Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "befe00dc3e29d1fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T13:32:18.066888Z",
     "start_time": "2025-10-02T13:32:18.018456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# python\n",
    "# Inspect TF-IDF vocabulary and top terms\n",
    "# Place this cell after you have fitted your TfidfVectorizer and obtained the TF-IDF matrix.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "# --- Adjust these names if your variables differ ---\n",
    "# Common variable names used in notebooks:\n",
    "# - fitted vectorizer: \"vectorizer\", \"tfidf_vectorizer\", \"tfidf\"\n",
    "# - TF-IDF matrix: \"X\", \"X_tfidf\", \"tfidf_matrix\"\n",
    "vectorizer = globals().get(\"vectorizer\") or globals().get(\"tfidf_vectorizer\") or globals().get(\"tfidf\")\n",
    "X = globals().get(\"X\") or globals().get(\"X_tfidf\") or globals().get(\"tfidf_matrix\")\n",
    "\n",
    "# If neither vectorizer nor X exist, try to fit quickly if a docs list is available\n",
    "if vectorizer is None and \"docs\" in globals():\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    vectorizer = TfidfVectorizer(**tfidf_kwargs)\n",
    "    X = vectorizer.fit_transform(docs)\n",
    "    print(\"Fitted a new vectorizer from 'docs' variable.\")\n",
    "elif vectorizer is None:\n",
    "    raise NameError(\n",
    "        \"Could not find a fitted vectorizer. Define `vectorizer` (or `tfidf_vectorizer`/`tfidf`) or provide `docs`.\")\n",
    "\n",
    "if X is None:\n",
    "    # try to transform if we have a docs variable\n",
    "    if \"docs\" in globals():\n",
    "        X = vectorizer.transform(docs)\n",
    "    else:\n",
    "        raise NameError(\"Could not find TF-IDF matrix `X` (or `X_tfidf`).\")\n",
    "\n",
    "# --- Basic vocabulary info ---\n",
    "features = vectorizer.get_feature_names_out()\n",
    "vocab_size = len(features)\n",
    "print(f\"Vocabulary size (after vectorizer filters): {vocab_size}\")\n",
    "\n",
    "# --- Inspect IDF values ---\n",
    "idf = np.array(vectorizer.idf_)\n",
    "idf_df = pd.DataFrame({\"term\": features, \"idf\": idf})\n",
    "idf_df_sorted = idf_df.sort_values(\"idf\")\n",
    "\n",
    "top_k = 25\n",
    "print(\"\\nMost common terms (lowest idf):\")\n",
    "print(idf_df_sorted.head(top_k).to_string(index=False))\n",
    "\n",
    "print(\"\\nRarest terms (highest idf):\")\n",
    "print(idf_df_sorted.tail(top_k).sort_values(\"idf\", ascending=False).to_string(index=False))\n",
    "\n",
    "# --- Top terms by average TF-IDF across documents ---\n",
    "if sparse.issparse(X):\n",
    "    mean_tfidf = np.asarray(X.mean(axis=0)).ravel()\n",
    "else:\n",
    "    mean_tfidf = np.array(X).mean(axis=0)\n",
    "\n",
    "tfidf_df = pd.DataFrame({\"term\": features, \"mean_tfidf\": mean_tfidf})\n",
    "tfidf_top = tfidf_df.sort_values(\"mean_tfidf\", ascending=False).head(top_k)\n",
    "print(f\"\\nTop {top_k} terms by mean TF-IDF across the corpus:\")\n",
    "print(tfidf_top.to_string(index=False))\n",
    "\n",
    "\n",
    "# --- Helper: top terms for one document (by document index) ---\n",
    "def top_terms_for_doc(doc_idx, top_n=15):\n",
    "    if doc_idx < 0 or doc_idx >= X.shape[0]:\n",
    "        raise IndexError(\"doc_idx out of range\")\n",
    "    row = X[doc_idx]\n",
    "    if sparse.issparse(row):\n",
    "        row = row.toarray().ravel()\n",
    "    else:\n",
    "        row = np.array(row).ravel()\n",
    "    nz_idx = np.argsort(row)[::-1][:top_n]\n",
    "    return pd.DataFrame({\"term\": features[nz_idx], \"tfidf\": row[nz_idx]})\n",
    "\n",
    "# Example usage:\n",
    "# print(top_terms_for_doc(0, top_n=20))"
   ],
   "id": "6ff8c5a9661baa9f",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[21]\u001B[39m\u001B[32m, line 14\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;66;03m# --- Adjust these names if your variables differ ---\u001B[39;00m\n\u001B[32m     10\u001B[39m \u001B[38;5;66;03m# Common variable names used in notebooks:\u001B[39;00m\n\u001B[32m     11\u001B[39m \u001B[38;5;66;03m# - fitted vectorizer: \"vectorizer\", \"tfidf_vectorizer\", \"tfidf\"\u001B[39;00m\n\u001B[32m     12\u001B[39m \u001B[38;5;66;03m# - TF-IDF matrix: \"X\", \"X_tfidf\", \"tfidf_matrix\"\u001B[39;00m\n\u001B[32m     13\u001B[39m vectorizer = \u001B[38;5;28mglobals\u001B[39m().get(\u001B[33m\"\u001B[39m\u001B[33mvectorizer\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mglobals\u001B[39m().get(\u001B[33m\"\u001B[39m\u001B[33mtfidf_vectorizer\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mglobals\u001B[39m().get(\u001B[33m\"\u001B[39m\u001B[33mtfidf\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m X = \u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mX\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mX_tfidf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtfidf_matrix\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[38;5;66;03m# If neither vectorizer nor X exist, try to fit quickly if a docs list is available\u001B[39;00m\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m vectorizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mdocs\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mglobals\u001B[39m():\n",
      "\u001B[31mValueError\u001B[39m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
