{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Fine Tune\n",
    "- RoBERTa\n",
    "- No need for inference speed up using distil bert since dataset is very small\n",
    "- Hyperparameter tuning using huggingfaces hyperparameter search\n",
    "- group k fold cross validation for prediction\n",
    "\n",
    "## Several conditions:\n",
    "- (spell corrected and) expanded prompts\n",
    "- raw conversational part\n"
   ],
   "id": "92df0da8972ba415"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:24:47.394826Z",
     "start_time": "2025-09-22T19:24:46.318585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ],
   "id": "26b5640ab14c7350",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:26:28.667941Z",
     "start_time": "2025-09-22T19:26:28.643552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn  = sqlite3.connect('../../../data/giicg.db')\n",
    "all_prompts = pd.read_sql(\"Select * from expanded_roberta_prompts\", conn)\n",
    "conn.close()"
   ],
   "id": "134310018dd52364",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check data",
   "id": "f0c085972651a4fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:26:31.099808Z",
     "start_time": "2025-09-22T19:26:31.080930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "users_per_gender = all_prompts.groupby('gender')['user_id'].nunique().reset_index(name='num_users')\n",
    "users_per_gender"
   ],
   "id": "cc639a91cdc93756",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              gender  num_users\n",
       "0    Man (cisgender)         15\n",
       "1  Woman (cisgender)         12"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>num_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Man (cisgender)</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Woman (cisgender)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:26:32.650007Z",
     "start_time": "2025-09-22T19:26:32.630288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages_per_user = all_prompts.groupby('user_id')['message_id'].nunique().reset_index(name='num_messages')\n",
    "messages_per_user"
   ],
   "id": "721f2c54de0aa65f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    user_id  num_messages\n",
       "0         6             9\n",
       "1         8             2\n",
       "2        11            11\n",
       "3        15             3\n",
       "4        16            25\n",
       "5        25             4\n",
       "6        28            22\n",
       "7        31             5\n",
       "8        34            66\n",
       "9        46             5\n",
       "10       47            51\n",
       "11       48            16\n",
       "12       55            36\n",
       "13       56             6\n",
       "14       60             7\n",
       "15       63             2\n",
       "16       65            10\n",
       "17       73            50\n",
       "18       77            20\n",
       "19       79            61\n",
       "20       81             5\n",
       "21       83            15\n",
       "22       88             5\n",
       "23       89            31\n",
       "24       90            14\n",
       "25       91            81\n",
       "26       92             5"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>num_messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>55</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>73</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>77</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>79</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>83</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>89</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>90</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>91</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Set up Model",
   "id": "cfc6626e5c9dbd42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T11:21:57.667150Z",
     "start_time": "2025-09-17T11:21:57.170716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "with open(\"../../prediction/finetune/label2id.json\", \"r\") as f:\n",
    "    label2id = json.load(f)\n",
    "\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "num_labels = len(label2id)\n",
    "\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=num_labels\n",
    "    )\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"conversational\"],\n",
    "        truncation=True,\n",
    "        padding=False # padding is handled in the data collator\n",
    "    )\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    precision = precision_score(labels, preds, average='weighted')\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ],
   "id": "3c8c51c6aa4e3e8e",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check max sample size",
   "id": "8d4237629185424b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T11:21:57.691727Z",
     "start_time": "2025-09-17T11:21:57.671572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "texts = all_prompts['conversational'].tolist()\n",
    "\n",
    "token_counts = [len(tokenizer.encode(text, add_special_tokens=True)) for text in texts]\n",
    "\n",
    "max_tokens = max(token_counts)\n",
    "min_tokens = min(token_counts)\n",
    "avg_tokens = sum(token_counts) / len(token_counts)\n",
    "\n",
    "print(f\"Max tokens: {max_tokens}\")\n",
    "print(f\"Min tokens: {min_tokens}\")\n"
   ],
   "id": "7497593ce0206095",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tokens: 407\n",
      "Min tokens: 4\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Cross Validation\n",
    "\n",
    "- selected hyperparameters: lr 3.2e-5, batchsizes 8, epochs 5"
   ],
   "id": "b18154b7d4cc2f1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T11:25:37.141722Z",
     "start_time": "2025-09-17T11:21:57.702260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "groups = all_prompts['user_id'].values\n",
    "texts = all_prompts['conversational'].tolist()\n",
    "labels = all_prompts['label'].tolist()\n",
    "n_splits = 5  # e.g. 5-fold CV\n",
    "\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(texts, labels, groups)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "\n",
    "    train_prompts = all_prompts.iloc[train_idx]\n",
    "    val_prompts = all_prompts.iloc[val_idx]\n",
    "\n",
    "    train_dataset = Dataset.from_pandas(train_prompts[['conversational', 'label']])\n",
    "    val_dataset = Dataset.from_pandas(val_prompts[['conversational', 'label']])\n",
    "\n",
    "    train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "    val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    # Set up Trainer with model/tokenizer/data_collator as before\n",
    "    trainer = Trainer(\n",
    "        model_init=model_init,\n",
    "        args=TrainingArguments(\n",
    "            output_dir=f\"./finetune/cross_validation/run_4/fold_{fold+1}_results\",\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            logging_dir=f\"./fold_{fold+1}_logs\",\n",
    "            per_device_train_batch_size=8,\n",
    "            per_device_eval_batch_size=8,\n",
    "            num_train_epochs=5,\n",
    "            learning_rate=3.2e-5,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            logging_steps=50,\n",
    "            logging_strategy=\"steps\",\n",
    "        ),\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_metrics = trainer.evaluate()\n",
    "    print(f\"Fold {fold + 1} metrics:\", eval_metrics)\n",
    "    all_results.append(eval_metrics)\n",
    "\n",
    "print(all_results)\n",
    "\n",
    "\n"
   ],
   "id": "591e7b302dd48833",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 453/453 [00:00<00:00, 66587.92 examples/s]\n",
      "Map: 100%|██████████| 114/114 [00:00<00:00, 32898.77 examples/s]\n",
      "/var/folders/_h/dm14sczn7s77lrr765t54y7h0000gn/T/ipykernel_60864/18244806.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [285/285 00:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.633500</td>\n",
       "      <td>1.396640</td>\n",
       "      <td>0.324561</td>\n",
       "      <td>0.468703</td>\n",
       "      <td>0.982900</td>\n",
       "      <td>0.324561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.436100</td>\n",
       "      <td>1.646291</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.498677</td>\n",
       "      <td>0.982918</td>\n",
       "      <td>0.350877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.313000</td>\n",
       "      <td>2.516136</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.611588</td>\n",
       "      <td>0.963846</td>\n",
       "      <td>0.456140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.134100</td>\n",
       "      <td>2.321332</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.704024</td>\n",
       "      <td>0.967456</td>\n",
       "      <td>0.561404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.149900</td>\n",
       "      <td>3.167446</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.594857</td>\n",
       "      <td>0.963081</td>\n",
       "      <td>0.438596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "bb9c5d5a8f64c51295af33a938f0930d"
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "5187c1c54f9f8696fde7240b00e102c4"
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 metrics: {'eval_loss': 2.3213324546813965, 'eval_accuracy': 0.5614035087719298, 'eval_f1': 0.7040240461293094, 'eval_precision': 0.9674561403508772, 'eval_recall': 0.5614035087719298, 'eval_runtime': 0.4168, 'eval_samples_per_second': 273.492, 'eval_steps_per_second': 35.986, 'epoch': 5.0}\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 454/454 [00:00<00:00, 64314.17 examples/s]\n",
      "Map: 100%|██████████| 113/113 [00:00<00:00, 29260.18 examples/s]\n",
      "/var/folders/_h/dm14sczn7s77lrr765t54y7h0000gn/T/ipykernel_60864/18244806.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [285/285 00:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.679400</td>\n",
       "      <td>0.805562</td>\n",
       "      <td>0.353982</td>\n",
       "      <td>0.274157</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.353982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.667500</td>\n",
       "      <td>0.632077</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>0.623761</td>\n",
       "      <td>0.612031</td>\n",
       "      <td>0.672566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.543100</td>\n",
       "      <td>0.856883</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>0.686300</td>\n",
       "      <td>0.789035</td>\n",
       "      <td>0.672566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.340300</td>\n",
       "      <td>1.003524</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>0.653008</td>\n",
       "      <td>0.741009</td>\n",
       "      <td>0.637168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.230100</td>\n",
       "      <td>1.114140</td>\n",
       "      <td>0.646018</td>\n",
       "      <td>0.661695</td>\n",
       "      <td>0.744885</td>\n",
       "      <td>0.646018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "35ef7fc525919f589707924395a20b77"
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "428d12c73f7789d3db6ad68d9dfdff6d"
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 metrics: {'eval_loss': 0.6320773363113403, 'eval_accuracy': 0.672566371681416, 'eval_f1': 0.6237607411202007, 'eval_precision': 0.6120305456588643, 'eval_recall': 0.672566371681416, 'eval_runtime': 0.4662, 'eval_samples_per_second': 242.407, 'eval_steps_per_second': 32.178, 'epoch': 5.0}\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 453/453 [00:00<00:00, 59737.78 examples/s]\n",
      "Map: 100%|██████████| 114/114 [00:00<00:00, 31113.40 examples/s]\n",
      "/var/folders/_h/dm14sczn7s77lrr765t54y7h0000gn/T/ipykernel_60864/18244806.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [285/285 00:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.672700</td>\n",
       "      <td>0.969304</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.472962</td>\n",
       "      <td>0.697931</td>\n",
       "      <td>0.456140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.461000</td>\n",
       "      <td>1.133397</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.607909</td>\n",
       "      <td>0.713605</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.258000</td>\n",
       "      <td>2.107358</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.554896</td>\n",
       "      <td>0.703083</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.245500</td>\n",
       "      <td>2.748728</td>\n",
       "      <td>0.517544</td>\n",
       "      <td>0.545838</td>\n",
       "      <td>0.699297</td>\n",
       "      <td>0.517544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>2.864187</td>\n",
       "      <td>0.535088</td>\n",
       "      <td>0.563860</td>\n",
       "      <td>0.706794</td>\n",
       "      <td>0.535088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "f20c62613048273f859a81910adc7939"
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "92fa8e885ff64d5f7152eaa059cdeae5"
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 metrics: {'eval_loss': 1.1333969831466675, 'eval_accuracy': 0.5789473684210527, 'eval_f1': 0.6079093902460049, 'eval_precision': 0.7136051335234638, 'eval_recall': 0.5789473684210527, 'eval_runtime': 0.3635, 'eval_samples_per_second': 313.616, 'eval_steps_per_second': 41.265, 'epoch': 5.0}\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 453/453 [00:00<00:00, 53884.45 examples/s]\n",
      "Map: 100%|██████████| 114/114 [00:00<00:00, 36891.49 examples/s]\n",
      "/var/folders/_h/dm14sczn7s77lrr765t54y7h0000gn/T/ipykernel_60864/18244806.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [285/285 00:43, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.681700</td>\n",
       "      <td>0.599319</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.695902</td>\n",
       "      <td>0.760671</td>\n",
       "      <td>0.710526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.497900</td>\n",
       "      <td>0.548933</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.760932</td>\n",
       "      <td>0.773338</td>\n",
       "      <td>0.763158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.289100</td>\n",
       "      <td>0.867413</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.776838</td>\n",
       "      <td>0.801587</td>\n",
       "      <td>0.780702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.250800</td>\n",
       "      <td>1.210691</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.776838</td>\n",
       "      <td>0.801587</td>\n",
       "      <td>0.780702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.194400</td>\n",
       "      <td>1.316027</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.753170</td>\n",
       "      <td>0.759498</td>\n",
       "      <td>0.754386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "10194f74180a883ee8ec5eea0597d036"
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "d35c1fa785706a3e48a2fa07a1dfa5a6"
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 metrics: {'eval_loss': 0.8674131035804749, 'eval_accuracy': 0.7807017543859649, 'eval_f1': 0.7768381489311722, 'eval_precision': 0.8015873015873016, 'eval_recall': 0.7807017543859649, 'eval_runtime': 0.3534, 'eval_samples_per_second': 322.549, 'eval_steps_per_second': 42.441, 'epoch': 5.0}\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 455/455 [00:00<00:00, 58543.72 examples/s]\n",
      "Map: 100%|██████████| 112/112 [00:00<00:00, 30826.30 examples/s]\n",
      "/var/folders/_h/dm14sczn7s77lrr765t54y7h0000gn/T/ipykernel_60864/18244806.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [285/285 00:40, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>1.383812</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.276603</td>\n",
       "      <td>0.906995</td>\n",
       "      <td>0.196429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.502100</td>\n",
       "      <td>1.107049</td>\n",
       "      <td>0.526786</td>\n",
       "      <td>0.655293</td>\n",
       "      <td>0.909306</td>\n",
       "      <td>0.526786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.296400</td>\n",
       "      <td>1.641585</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>0.647657</td>\n",
       "      <td>0.908464</td>\n",
       "      <td>0.517857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.329300</td>\n",
       "      <td>3.343460</td>\n",
       "      <td>0.401786</td>\n",
       "      <td>0.539513</td>\n",
       "      <td>0.894404</td>\n",
       "      <td>0.401786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>3.331898</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.566042</td>\n",
       "      <td>0.898283</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "fc70d30b1efe4f6676becfc44de3ec16"
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "b7e19d94cf5bf63a13bf6e2a61b57fe0"
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 metrics: {'eval_loss': 1.1070492267608643, 'eval_accuracy': 0.5267857142857143, 'eval_f1': 0.6552927978629208, 'eval_precision': 0.9093063186813186, 'eval_recall': 0.5267857142857142, 'eval_runtime': 0.4726, 'eval_samples_per_second': 236.99, 'eval_steps_per_second': 29.624, 'epoch': 5.0}\n",
      "[{'eval_loss': 2.3213324546813965, 'eval_accuracy': 0.5614035087719298, 'eval_f1': 0.7040240461293094, 'eval_precision': 0.9674561403508772, 'eval_recall': 0.5614035087719298, 'eval_runtime': 0.4168, 'eval_samples_per_second': 273.492, 'eval_steps_per_second': 35.986, 'epoch': 5.0}, {'eval_loss': 0.6320773363113403, 'eval_accuracy': 0.672566371681416, 'eval_f1': 0.6237607411202007, 'eval_precision': 0.6120305456588643, 'eval_recall': 0.672566371681416, 'eval_runtime': 0.4662, 'eval_samples_per_second': 242.407, 'eval_steps_per_second': 32.178, 'epoch': 5.0}, {'eval_loss': 1.1333969831466675, 'eval_accuracy': 0.5789473684210527, 'eval_f1': 0.6079093902460049, 'eval_precision': 0.7136051335234638, 'eval_recall': 0.5789473684210527, 'eval_runtime': 0.3635, 'eval_samples_per_second': 313.616, 'eval_steps_per_second': 41.265, 'epoch': 5.0}, {'eval_loss': 0.8674131035804749, 'eval_accuracy': 0.7807017543859649, 'eval_f1': 0.7768381489311722, 'eval_precision': 0.8015873015873016, 'eval_recall': 0.7807017543859649, 'eval_runtime': 0.3534, 'eval_samples_per_second': 322.549, 'eval_steps_per_second': 42.441, 'epoch': 5.0}, {'eval_loss': 1.1070492267608643, 'eval_accuracy': 0.5267857142857143, 'eval_f1': 0.6552927978629208, 'eval_precision': 0.9093063186813186, 'eval_recall': 0.5267857142857142, 'eval_runtime': 0.4726, 'eval_samples_per_second': 236.99, 'eval_steps_per_second': 29.624, 'epoch': 5.0}]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T11:25:37.172076Z",
     "start_time": "2025-09-17T11:25:37.165222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = pd.DataFrame(all_results)\n",
    "stats = results.describe()\n",
    "with open(\"stats.tex\", \"w\") as f:\n",
    "    stats.to_latex(f)\n"
   ],
   "id": "aba3e24c8fdb3278",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T11:25:37.180393Z",
     "start_time": "2025-09-17T11:25:37.176539Z"
    }
   },
   "cell_type": "code",
   "source": "stats",
   "id": "a9f033108d5bd678",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       eval_loss  eval_accuracy   eval_f1  eval_precision  eval_recall  \\\n",
       "count   5.000000       5.000000  5.000000        5.000000     5.000000   \n",
       "mean    1.212254       0.624081  0.673565        0.800797     0.624081   \n",
       "std     0.652469       0.102850  0.068407        0.143862     0.102850   \n",
       "min     0.632077       0.526786  0.607909        0.612031     0.526786   \n",
       "25%     0.867413       0.561404  0.623761        0.713605     0.561404   \n",
       "50%     1.107049       0.578947  0.655293        0.801587     0.578947   \n",
       "75%     1.133397       0.672566  0.704024        0.909306     0.672566   \n",
       "max     2.321332       0.780702  0.776838        0.967456     0.780702   \n",
       "\n",
       "       eval_runtime  eval_samples_per_second  eval_steps_per_second  epoch  \n",
       "count      5.000000                  5.00000               5.000000    5.0  \n",
       "mean       0.414500                277.81080              36.298800    5.0  \n",
       "std        0.055651                 39.43963               5.568248    0.0  \n",
       "min        0.353400                236.99000              29.624000    5.0  \n",
       "25%        0.363500                242.40700              32.178000    5.0  \n",
       "50%        0.416800                273.49200              35.986000    5.0  \n",
       "75%        0.466200                313.61600              41.265000    5.0  \n",
       "max        0.472600                322.54900              42.441000    5.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.212254</td>\n",
       "      <td>0.624081</td>\n",
       "      <td>0.673565</td>\n",
       "      <td>0.800797</td>\n",
       "      <td>0.624081</td>\n",
       "      <td>0.414500</td>\n",
       "      <td>277.81080</td>\n",
       "      <td>36.298800</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.652469</td>\n",
       "      <td>0.102850</td>\n",
       "      <td>0.068407</td>\n",
       "      <td>0.143862</td>\n",
       "      <td>0.102850</td>\n",
       "      <td>0.055651</td>\n",
       "      <td>39.43963</td>\n",
       "      <td>5.568248</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.632077</td>\n",
       "      <td>0.526786</td>\n",
       "      <td>0.607909</td>\n",
       "      <td>0.612031</td>\n",
       "      <td>0.526786</td>\n",
       "      <td>0.353400</td>\n",
       "      <td>236.99000</td>\n",
       "      <td>29.624000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.867413</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.623761</td>\n",
       "      <td>0.713605</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.363500</td>\n",
       "      <td>242.40700</td>\n",
       "      <td>32.178000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.107049</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.655293</td>\n",
       "      <td>0.801587</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>273.49200</td>\n",
       "      <td>35.986000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.133397</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>0.704024</td>\n",
       "      <td>0.909306</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>0.466200</td>\n",
       "      <td>313.61600</td>\n",
       "      <td>41.265000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.321332</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.776838</td>\n",
       "      <td>0.967456</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.472600</td>\n",
       "      <td>322.54900</td>\n",
       "      <td>42.441000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T11:25:52.431307Z",
     "start_time": "2025-09-17T11:25:52.223442Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.save_model(\"finetune/best_model\")",
   "id": "b22fbf8c6a0cbebb",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Get Validation set from best fold (4th)",
   "id": "52cf6a03971b5aa0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:33:07.072542Z",
     "start_time": "2025-09-22T19:33:07.039192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "groups = all_prompts['user_id'].values\n",
    "texts = all_prompts['conversational'].tolist()\n",
    "labels = all_prompts['label'].tolist()\n",
    "n_splits = 5\n",
    "\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "# Get validation indices for the 4th fold (fold==3)\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(texts, labels, groups)):\n",
    "    if fold == 3:\n",
    "        val_prompts_4th = all_prompts.iloc[val_idx]\n",
    "        val_dataset_4th = val_prompts_4th[['conversational', 'label']]\n",
    "        break\n",
    "val_dataset_4th\n"
   ],
   "id": "ed61940fc3507e15",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                        conversational  label\n",
       "48   what is the best way to encode and compress a ...      0\n",
       "49   does lzstring also work in the browser, client...      0\n",
       "50   Is there a way in typescript to cast to a type...      0\n",
       "51   I would like to distill a type based on an inc...      0\n",
       "150                  can you create Photoshop Scripts?      0\n",
       "..                                                 ...    ...\n",
       "412  can you update directly the folder iterative c...      1\n",
       "413  super, now can you give me latex formula for t...      1\n",
       "414                              yes latex code please      1\n",
       "515       I am working on the problem of reconstruc...      0\n",
       "516  Focus on one step at the time. Write what is t...      0\n",
       "\n",
       "[114 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversational</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>what is the best way to encode and compress a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>does lzstring also work in the browser, client...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Is there a way in typescript to cast to a type...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>I would like to distill a type based on an inc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>can you create Photoshop Scripts?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>can you update directly the folder iterative c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>super, now can you give me latex formula for t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>yes latex code please</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>I am working on the problem of reconstruc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Focus on one step at the time. Write what is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## save to db",
   "id": "e150131dfdf75575"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:42:49.715260Z",
     "start_time": "2025-09-22T19:42:49.702912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conn  = sqlite3.connect('../../../data/giicg.db')\n",
    "val_dataset_4th.to_sql(\"validation_set\", conn, if_exists=\"replace\", index=False)"
   ],
   "id": "88404029faff3963",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "681491c906973025"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
